{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1 - A first look at Neural Networks\n",
    "\n",
    "In this session we implement a fully connected Neural Network by hand. We will only use Numpy to handle the tensors. We do the backpropagation by hand given a cross entropy loss function.\n",
    "\n",
    "All packages used over the next few days can be installed with\n",
    "\n",
    "```console\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "We will train the neural network on the problem of whether a given line bundle has slope zero somewhere in the Kähler cone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NN implementation\n",
    "\n",
    "We recall a Neural Network acts by iteratively applying matrix multiplications with subsequent non linearites:\n",
    "\n",
    "$$\n",
    "z_{i+1} = \\sigma( W_i \\cdot z_{i} + b_i)\n",
    "$$\n",
    "\n",
    "For our initial network we want to study a classification problem with two Classes. Since, this is a classification problem we make use of the softmax activation function in the last layer. Furthermore, we also want to have the option to use the ReLU and sigmoid activation functions in the intermediate layers:\n",
    "\n",
    "$$\n",
    "\\text{softmax} (x_i) = p(x_i) = \\frac{e^{x_i}}{\\sum_i e^{x_i}}.\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\text{relu} (x) = \\begin{cases}\n",
    "x \\text{ if } x > 0 \\\\\n",
    "0 \\text{ else}\n",
    "\\end{cases}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\text{sigmoid} (x) = \\frac{1}{1+e^{-x}}.\n",
    "$$\n",
    "\n",
    "Let's get started by implementing the neural network class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, nInput, nLayer, nClasses, nHidden, activation):\n",
    "        \n",
    "        shapes = [nInput] + [nHidden for _ in range(nLayer)] + [nClasses]\n",
    "        self.b = [np.zeros(shapes[i+1]) for i in range(nLayer+1)]\n",
    "        self.W = [np.zeros((shapes[i], shapes[i+1])) for i in range(nLayer+1)]\n",
    "        self.act = [activation for _ in range(nLayer)] + ['softmax'] \n",
    "        self.nLayer = nLayer+1\n",
    "        self.nClasses = nClasses\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self,mu = 0, sigma = 0.2):\n",
    "        for i in range(self.nLayer):\n",
    "            self.W[i] = np.random.normal(mu, sigma, np.shape(self.W[i]))\n",
    "            self.b[i] = np.random.normal(mu, sigma, np.shape(self.b[i]))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-1*x))\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.where(x > 0, x, 0)\n",
    "    \n",
    "    def forward(self, x, i):\n",
    "        return np.dot(x, self.W[i]) + self.b[i]\n",
    "    \n",
    "    def act_forward(self, x, act):\n",
    "        return act(x)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        # introuce numerical stability\n",
    "        x_stable = x-np.max(x)\n",
    "        e = np.exp(x_stable)\n",
    "        s = np.multiply(e, np.reshape(1/np.sum(e, axis=1), (x.shape[0],1)))\n",
    "        return s\n",
    "    \n",
    "    def activation(self, i):\n",
    "        if self.act[i] == 'relu':\n",
    "            return self.relu\n",
    "        elif self.act[i] == 'sigmoid':\n",
    "            return self.sigmoid\n",
    "        elif self.act[i] == 'softmax':\n",
    "            return self.softmax\n",
    "        \n",
    "    def predict(self, x, train = True):\n",
    "        # zk = regression\n",
    "        zk = []\n",
    "        # ak = act(zk)\n",
    "        ak = [np.copy(x)]\n",
    "        for i in range(len(self.W)):\n",
    "            zk += [self.forward(ak[-1], i)]\n",
    "            ak += [self.act_forward(zk[-1], self.activation(i))]\n",
    "            \n",
    "        pred = ak[-1]\n",
    "            \n",
    "        if train:\n",
    "            return pred, {'zk': zk, 'ak': ak}\n",
    "        else:\n",
    "            return pred\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        z = x\n",
    "        for i in range(self.nLayer):\n",
    "            z = self.act_forward(self.forward(z, i), self.activation(i))\n",
    "        return z.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The optimizer implementation\n",
    "\n",
    "In this section we implement the optimizer. This class will need access to the neural network weights and biases. We further need the derivatives to implement the backpropagation.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{softmax}_j (x)}{\\partial x_k} = \\begin{cases} p_j(x) ( 1- p_k(x)) \\qquad &\\text{for j=k} \\\\\n",
    "- p(x_j) p(x_k) \\qquad \\qquad &\\text{for i $\\neq$ j}\n",
    "\\end{cases}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial \\text{relu} (x)}{\\partial x} = \\begin{cases}\n",
    "1 \\text{ if } x > 0 \\\\\n",
    "0 \\text{ else}\n",
    "\\end{cases}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial \\text{sigmoid} (x)}{\\partial x} = \\text{sigmoid}(x) (1 - \\text{sigmoid}(x)).\n",
    "$$\n",
    "\n",
    "The cross entropy loss for a single datapoint is defined as\n",
    "\n",
    "$$\n",
    "L = - \\sum_j y_j \\log (a_j)\n",
    "$$\n",
    "\n",
    "where $y$ is the true label and $z$ is the predicted probability. Thus, when implementing the backpropagation we arrive at\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial p_j} = p_j - y_j.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optimizer:\n",
    "    def __init__(self, NN, lr):\n",
    "        self.NN = NN\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update_weights(self, dw, db):\n",
    "        for i in range(self.NN.nLayer):\n",
    "            self.NN.W[i] -= self.lr*dw[-1-i]\n",
    "            self.NN.b[i] -= self.lr*db[-1-i]\n",
    "            \n",
    "    def act_backward(self, zk, act):\n",
    "        if act == 'relu':\n",
    "            return self.relu_back(zk)\n",
    "        elif act == 'sigmoid':\n",
    "            return self.sigmoid_back(zk)\n",
    "    \n",
    "    def linear_backward(self, d, i):\n",
    "        return np.dot(d, self.NN.W[i].T)\n",
    "    \n",
    "    def relu_back(self, x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "    \n",
    "    def sigmoid_back(self, x):\n",
    "        s = self.NN.sigmoid(x)\n",
    "        return s*(1-s)\n",
    "        \n",
    "    def partial_theta(self, y, zk, ak):\n",
    "        dw = []\n",
    "        db = []\n",
    "        nSample = y.shape[0]\n",
    "        \n",
    "        #first the cross entropy loss deriv\n",
    "        d = [ak[-1]-y]\n",
    "        # initialize the first dw db derivatives\n",
    "        dw += [np.dot(np.transpose(ak[-2]), d[0])/nSample]\n",
    "        db += [np.sum(d[0], axis=0)/nSample]\n",
    "\n",
    "        #next we loop over all other layers\n",
    "        for i in reversed(range(self.NN.nLayer-1)):\n",
    "            activation = self.act_backward(zk[i], self.NN.act[i])\n",
    "            lb = self.linear_backward(d[self.NN.nLayer-2-i], i+1)\n",
    "            d += [lb*activation]\n",
    "            dw += [np.dot(ak[i].T, d[-1])/nSample]\n",
    "            db += [np.sum(d[-1], axis=0)/nSample]\n",
    "            \n",
    "        return dw, db\n",
    "    \n",
    "    def compute_loss(self, ypred, ytrue, eps=1e-7):\n",
    "        #crossentropy\n",
    "        y_label = ytrue.argmax(axis=1)\n",
    "        loss = (-1)*np.mean(np.log(ypred[range(len(ypred)), y_label]+eps))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training loop\n",
    "\n",
    "We write a training loop that takes as arguments the training and test data, the NN, the optimizer, the (mini) batch size and the number of training Epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(train_data, test_data, NN, optimizer, nEpochs, bSize):\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    x_train, y_train = train_data\n",
    "    x_test, y_test = test_data\n",
    "    steps = int(x_train.shape[0]/bSize)\n",
    "    #t = trange(nEpochs)\n",
    "    for i in range(nEpochs):\n",
    "        shuffled_indices = np.arange(len(x_train))\n",
    "        np.random.shuffle(shuffled_indices)\n",
    "        x_train = x_train[shuffled_indices]\n",
    "        y_train = y_train[shuffled_indices]\n",
    "        for j in range(steps):\n",
    "            x_mini, y_mini = x_train[j*bSize:(j+1)*bSize], y_train[j*bSize:(j+1)*bSize]\n",
    "            y_pred, inter = NN.predict(x_mini)\n",
    "            # next we backpropagate\n",
    "            dw, db = optimizer.partial_theta(y_mini, inter['zk'], inter['ak'])\n",
    "            optimizer.update_weights(dw, db)\n",
    "            train_loss += [optimizer.compute_loss(y_pred, y_mini)]\n",
    "        test_loss += [optimizer.compute_loss(NN.predict(x_test, False), y_test)]\n",
    "        train_accuracy += [np.sum(NN(x_train) == y_train.argmax(axis=-1))/len(x_train)]\n",
    "        test_accuracy += [np.sum(NN(x_test) == y_test.argmax(axis=-1))/len(x_test)]\n",
    "        # t.set_description\n",
    "        print('Epoch {}. Train acc: {}, Test acc: {}.'.format(1+i,\n",
    "                                train_accuracy[-1], test_accuracy[-1]))\n",
    "    loss = {'train_loss': train_loss, 'test_loss': test_loss, \n",
    "            'train_accuracy': train_accuracy, 'test_accuracy': test_accuracy}\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "We want to investigate whether a given line bundle over a CICY is slope stable somewhere in the Kähler cone. This amounts to solving the following constraints:\n",
    "\n",
    "$$\n",
    "\\mu(L) = d_{ijk} q^i t^j t^k = 0 \\qquad \\forall t^j > 0 \\\\\n",
    "$$\n",
    "\n",
    "This question was investigated first in varied form by [Fabian Ruehle](https://arxiv.org/pdf/1706.07024.pdf). Take the bicubic:\n",
    "\n",
    "$$\n",
    "M = \\left[\n",
    "\\begin{array}{c||c}\n",
    "2 & 3\\\\\n",
    "2 & 3\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "which has slope constraint [with some abuse of notation]:\n",
    "$$\n",
    "\\mu(L) = 6m_0t_0t_1 + 3m_0t_1^2 + 3m_1t_0^2 + 6m_1t_0t_1.\n",
    "$$\n",
    "We will generate data using the [pyCICY](https://github.com/robin-schneider/CICY) package for line bundles with charges in the range {-10, ... ,10}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyCICY import CICY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = CICY([[2,3],[2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0*m0*t0*t1 + 3.0*m0*t1**2 + 3.0*m1*t0**2 + 6.0*m1*t0*t1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.line_slope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmax = 10\n",
    "x = np.zeros((2*kmax+1, 2*kmax+1, 2))\n",
    "y = np.zeros((2*kmax+1, 2*kmax+1), dtype=np.int)\n",
    "for i in range(-kmax, kmax+1):\n",
    "    for j in range(-kmax, kmax+1):\n",
    "        x[i,j] = np.array([i,j])\n",
    "        y[i,j] = M.l_slope([i,j])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network\n",
    "\n",
    "Next we want to train the network. First we manipulate the data into a shuffled train and test split. Then, we set some hyperparameters and construct our Neural Network and optimizer. Finally, we train using our custom training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441, 2) (441, 2)\n"
     ]
    }
   ],
   "source": [
    "x = x.reshape((-1, 2))\n",
    "y = y.reshape((-1,1))\n",
    "y = np.eye(2)[y].reshape((-1,2)) #one-hot-encoding\n",
    "print(x.shape, y.shape)\n",
    "shuffled_indices = np.arange(len(x))\n",
    "np.random.shuffle(shuffled_indices)\n",
    "x = x[shuffled_indices]\n",
    "y = y[shuffled_indices]\n",
    "train_indices = int(0.8*len(x))\n",
    "train_data = (x[0:train_indices], y[0:train_indices])\n",
    "test_data = (x[train_indices:], y[train_indices:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nHidden = 64\n",
    "nLayers = 1\n",
    "act = 'relu'\n",
    "lr = 0.001\n",
    "nCharges = 2\n",
    "nClasses = 2\n",
    "nEpoch = 100\n",
    "bSize = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(nCharges, nLayers, nClasses, nHidden, act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizer(model, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Train acc: 0.4119318181818182, Test acc: 0.33707865168539325.\n",
      "Epoch 2. Train acc: 0.42329545454545453, Test acc: 0.34831460674157305.\n",
      "Epoch 3. Train acc: 0.4346590909090909, Test acc: 0.3595505617977528.\n",
      "Epoch 4. Train acc: 0.4403409090909091, Test acc: 0.4157303370786517.\n",
      "Epoch 5. Train acc: 0.45738636363636365, Test acc: 0.42696629213483145.\n",
      "Epoch 6. Train acc: 0.4715909090909091, Test acc: 0.48314606741573035.\n",
      "Epoch 7. Train acc: 0.4914772727272727, Test acc: 0.5056179775280899.\n",
      "Epoch 8. Train acc: 0.5511363636363636, Test acc: 0.5842696629213483.\n",
      "Epoch 9. Train acc: 0.6136363636363636, Test acc: 0.651685393258427.\n",
      "Epoch 10. Train acc: 0.6704545454545454, Test acc: 0.7415730337078652.\n",
      "Epoch 11. Train acc: 0.71875, Test acc: 0.7752808988764045.\n",
      "Epoch 12. Train acc: 0.7528409090909091, Test acc: 0.8202247191011236.\n",
      "Epoch 13. Train acc: 0.7840909090909091, Test acc: 0.8314606741573034.\n",
      "Epoch 14. Train acc: 0.8153409090909091, Test acc: 0.8539325842696629.\n",
      "Epoch 15. Train acc: 0.8295454545454546, Test acc: 0.8539325842696629.\n",
      "Epoch 16. Train acc: 0.8494318181818182, Test acc: 0.8539325842696629.\n",
      "Epoch 17. Train acc: 0.8579545454545454, Test acc: 0.8651685393258427.\n",
      "Epoch 18. Train acc: 0.8664772727272727, Test acc: 0.8651685393258427.\n",
      "Epoch 19. Train acc: 0.8835227272727273, Test acc: 0.8651685393258427.\n",
      "Epoch 20. Train acc: 0.8835227272727273, Test acc: 0.8876404494382022.\n",
      "Epoch 21. Train acc: 0.8920454545454546, Test acc: 0.898876404494382.\n",
      "Epoch 22. Train acc: 0.8948863636363636, Test acc: 0.9101123595505618.\n",
      "Epoch 23. Train acc: 0.9034090909090909, Test acc: 0.9213483146067416.\n",
      "Epoch 24. Train acc: 0.9147727272727273, Test acc: 0.9213483146067416.\n",
      "Epoch 25. Train acc: 0.9261363636363636, Test acc: 0.9325842696629213.\n",
      "Epoch 26. Train acc: 0.9261363636363636, Test acc: 0.9325842696629213.\n",
      "Epoch 27. Train acc: 0.9318181818181818, Test acc: 0.9325842696629213.\n",
      "Epoch 28. Train acc: 0.9346590909090909, Test acc: 0.9325842696629213.\n",
      "Epoch 29. Train acc: 0.9375, Test acc: 0.9438202247191011.\n",
      "Epoch 30. Train acc: 0.9488636363636364, Test acc: 0.9438202247191011.\n",
      "Epoch 31. Train acc: 0.9517045454545454, Test acc: 0.9438202247191011.\n",
      "Epoch 32. Train acc: 0.9545454545454546, Test acc: 0.9438202247191011.\n",
      "Epoch 33. Train acc: 0.9602272727272727, Test acc: 0.9550561797752809.\n",
      "Epoch 34. Train acc: 0.9602272727272727, Test acc: 0.9550561797752809.\n",
      "Epoch 35. Train acc: 0.9630681818181818, Test acc: 0.9550561797752809.\n",
      "Epoch 36. Train acc: 0.9659090909090909, Test acc: 0.9550561797752809.\n",
      "Epoch 37. Train acc: 0.96875, Test acc: 0.9550561797752809.\n",
      "Epoch 38. Train acc: 0.9715909090909091, Test acc: 0.9550561797752809.\n",
      "Epoch 39. Train acc: 0.9744318181818182, Test acc: 0.9550561797752809.\n",
      "Epoch 40. Train acc: 0.9744318181818182, Test acc: 0.9550561797752809.\n",
      "Epoch 41. Train acc: 0.9772727272727273, Test acc: 0.9550561797752809.\n",
      "Epoch 42. Train acc: 0.9801136363636364, Test acc: 0.9550561797752809.\n",
      "Epoch 43. Train acc: 0.9801136363636364, Test acc: 0.9662921348314607.\n",
      "Epoch 44. Train acc: 0.9801136363636364, Test acc: 0.9775280898876404.\n",
      "Epoch 45. Train acc: 0.9829545454545454, Test acc: 0.9775280898876404.\n",
      "Epoch 46. Train acc: 0.9829545454545454, Test acc: 0.9775280898876404.\n",
      "Epoch 47. Train acc: 0.9829545454545454, Test acc: 0.9775280898876404.\n",
      "Epoch 48. Train acc: 0.9857954545454546, Test acc: 0.9775280898876404.\n",
      "Epoch 49. Train acc: 0.9857954545454546, Test acc: 0.9775280898876404.\n",
      "Epoch 50. Train acc: 0.9857954545454546, Test acc: 0.9775280898876404.\n",
      "Epoch 51. Train acc: 0.9857954545454546, Test acc: 0.9775280898876404.\n",
      "Epoch 52. Train acc: 0.9886363636363636, Test acc: 0.9775280898876404.\n",
      "Epoch 53. Train acc: 0.9886363636363636, Test acc: 0.9887640449438202.\n",
      "Epoch 54. Train acc: 0.9886363636363636, Test acc: 0.9887640449438202.\n",
      "Epoch 55. Train acc: 0.9886363636363636, Test acc: 0.9887640449438202.\n",
      "Epoch 56. Train acc: 0.9886363636363636, Test acc: 0.9887640449438202.\n",
      "Epoch 57. Train acc: 0.9914772727272727, Test acc: 0.9887640449438202.\n",
      "Epoch 58. Train acc: 0.9914772727272727, Test acc: 0.9887640449438202.\n",
      "Epoch 59. Train acc: 0.9914772727272727, Test acc: 0.9887640449438202.\n",
      "Epoch 60. Train acc: 0.9943181818181818, Test acc: 0.9887640449438202.\n",
      "Epoch 61. Train acc: 0.9943181818181818, Test acc: 0.9887640449438202.\n",
      "Epoch 62. Train acc: 0.9943181818181818, Test acc: 1.0.\n",
      "Epoch 63. Train acc: 0.9943181818181818, Test acc: 1.0.\n",
      "Epoch 64. Train acc: 0.9943181818181818, Test acc: 1.0.\n",
      "Epoch 65. Train acc: 0.9943181818181818, Test acc: 1.0.\n",
      "Epoch 66. Train acc: 0.9943181818181818, Test acc: 1.0.\n",
      "Epoch 67. Train acc: 0.9971590909090909, Test acc: 1.0.\n",
      "Epoch 68. Train acc: 0.9971590909090909, Test acc: 1.0.\n",
      "Epoch 69. Train acc: 0.9971590909090909, Test acc: 1.0.\n",
      "Epoch 70. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 71. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 72. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 73. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 74. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 75. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 76. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 77. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 78. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 79. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 80. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 81. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 82. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 83. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 84. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 85. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 86. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 87. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 88. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 89. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 90. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 91. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 92. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 93. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 94. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 95. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 96. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 97. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 98. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 99. Train acc: 1.0, Test acc: 1.0.\n",
      "Epoch 100. Train acc: 1.0, Test acc: 1.0.\n"
     ]
    }
   ],
   "source": [
    "stats = training_loop(train_data, test_data, model, opt, nEpoch, bSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a closer look at these results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf4e728f98>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(stats['train_accuracy']))+1, stats['train_accuracy'], color='red', label='train')\n",
    "plt.plot(np.arange(len(stats['test_accuracy']))+1, stats['test_accuracy'], color='blue', label='test')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf4c26f6a0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratio = len(stats['train_loss']) / len(stats['test_loss']) \n",
    "plt.plot(np.arange(len(stats['train_loss'])), stats['train_loss'], color='red', label='train')\n",
    "plt.plot(np.arange(1, len(stats['test_loss'])+1)*ratio, stats['test_loss'], color='blue', label='test')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "\n",
    "In this section we implement the same NN in tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tfk = tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfmodel = tfk.Sequential()\n",
    "tfmodel.add(tfk.Input(shape=(2)))\n",
    "for i in range(nLayers):\n",
    "    tfmodel.add(tfk.layers.Dense(nHidden, activation=act))\n",
    "tfmodel.add(tfk.layers.Dense(nClasses))\n",
    "loss_fn = tfk.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "tfmodel.compile(optimizer=tfk.optimizers.SGD(learning_rate=lr), \n",
    "                loss=loss_fn,\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have a look at the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                192       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tfmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.0592 - accuracy: 0.4744 - val_loss: 1.1441 - val_accuracy: 0.5056\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9194 - accuracy: 0.5398 - val_loss: 0.9782 - val_accuracy: 0.5506\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8025 - accuracy: 0.5852 - val_loss: 0.8367 - val_accuracy: 0.5618\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.6335 - val_loss: 0.7199 - val_accuracy: 0.5618\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.6591 - val_loss: 0.6257 - val_accuracy: 0.5730\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.6903 - val_loss: 0.5529 - val_accuracy: 0.6067\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7301 - val_loss: 0.4981 - val_accuracy: 0.6854\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7869 - val_loss: 0.4564 - val_accuracy: 0.7753\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8324 - val_loss: 0.4240 - val_accuracy: 0.8539\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8580 - val_loss: 0.3983 - val_accuracy: 0.8989\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8892 - val_loss: 0.3774 - val_accuracy: 0.9213\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.9062 - val_loss: 0.3601 - val_accuracy: 0.9213\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.9176 - val_loss: 0.3452 - val_accuracy: 0.9326\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.9318 - val_loss: 0.3322 - val_accuracy: 0.9326\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.9375 - val_loss: 0.3208 - val_accuracy: 0.9663\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.9432 - val_loss: 0.3107 - val_accuracy: 0.9775\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.9545 - val_loss: 0.3015 - val_accuracy: 0.9775\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.9545 - val_loss: 0.2932 - val_accuracy: 0.9775\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.9631 - val_loss: 0.2856 - val_accuracy: 0.9775\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.9631 - val_loss: 0.2783 - val_accuracy: 0.9775\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.9659 - val_loss: 0.2714 - val_accuracy: 0.9775\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.9716 - val_loss: 0.2651 - val_accuracy: 0.9775\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.9688 - val_loss: 0.2591 - val_accuracy: 0.9775\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.9744 - val_loss: 0.2535 - val_accuracy: 0.9775\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.9801 - val_loss: 0.2481 - val_accuracy: 0.9775\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.9886 - val_loss: 0.2431 - val_accuracy: 0.9775\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.9943 - val_loss: 0.2385 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2389 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 1.0000 - val_loss: 0.1683 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1801 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1708 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1682 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 1.0000 - val_loss: 0.1454 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1584 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1540 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = tfmodel.fit(x, y.argmax(-1), epochs=100,\n",
    "            batch_size=bSize, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have a look at the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdedc386c88>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(stats['accuracy']))+1, stats['accuracy'], color='red', label='train')\n",
    "plt.plot(np.arange(len(stats['val_accuracy']))+1, stats['val_accuracy'], color='blue', label='test')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Pen and Paper:\n",
    "1. Convince yourself of the equations in the slides. Add the missing indices?\n",
    "2. Compute $\\partial_j J$ for the crossentropy loss in the case of softmax and logistic in the last layer. Eq (28) and (32) in the slides.\n",
    "\n",
    "Deep Learning exercises:\n",
    "1. Implement more activation functions, such as leaky relu or tanh\n",
    "2. Use logistic/sigmoid in the last layer since we only have a 2 Classes classification problem.\n",
    "\n",
    "Physics exercises:\n",
    "1. Predict Hodge numbers; Data can be created with pyCICY package, but is also found in the github repository.\n",
    "    1. as Classification problem, with e.g. five classes being: $h^1 = {0,1,2,3,>3}$.\n",
    "    2. as Regression problem, $h^1 \\in \\mathbb{Z}_{\\ge 0}$. Reproduce results of Fabians paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hodge numbers of line bundles\n",
    "\n",
    "Hodge numbers of line bundles were one of the [first](https://arxiv.org/pdf/1706.07024.pdf) applications of ML techniques. Neural networks tend to have a harder time in regression problems and often do significantly better in classification problems. Thus, in [later](https://arxiv.org/pdf/1809.02547.pdf) [developments](https://arxiv.org/pdf/1906.08730.pdf) the focus was to identify polynomial cones of the hodge numbers.\n",
    "\n",
    "I've still got some data from our polynomial [paper](https://arxiv.org/pdf/1906.00392.pdf) where we used conventional curve fitting to identify the cones and their analytic expressions.\n",
    "\n",
    "You are welcome to use the data and reproduce these papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m0</th>\n",
       "      <th>m1</th>\n",
       "      <th>h0</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1861.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2484.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       m0    m1      h0   h1   h2    h3\n",
       "0   -10.0 -10.0     0.0  0.0  0.0  4060\n",
       "1   -10.0  -9.0     0.0  0.0  0.0  3215\n",
       "2   -10.0  -8.0     0.0  0.0  0.0  2484\n",
       "3   -10.0  -7.0     0.0  0.0  0.0  1861\n",
       "4   -10.0  -6.0     0.0  0.0  0.0  1340\n",
       "..    ...   ...     ...  ...  ...   ...\n",
       "436  10.0   6.0  1340.0  0.0  0.0     0\n",
       "437  10.0   7.0  1861.0  0.0  0.0     0\n",
       "438  10.0   8.0  2484.0  0.0  0.0     0\n",
       "439  10.0   9.0  3215.0  0.0  0.0     0\n",
       "440  10.0  10.0  4060.0  0.0  0.0     0\n",
       "\n",
       "[441 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h7806 = pd.read_csv('data/hodge/7806.csv', sep=' ', index_col=0)\n",
    "h7806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m0</th>\n",
       "      <th>m1</th>\n",
       "      <th>h0</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2975.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       m0    m1      h0   h1   h2    h3\n",
       "0   -10.0 -10.0     0.0  0.0  0.0  3730\n",
       "1   -10.0  -9.0     0.0  0.0  0.0  2975\n",
       "2   -10.0  -8.0     0.0  0.0  0.0  2316\n",
       "3   -10.0  -7.0     0.0  0.0  0.0  1749\n",
       "4   -10.0  -6.0     0.0  0.0  0.0  1270\n",
       "..    ...   ...     ...  ...  ...   ...\n",
       "436  10.0   6.0  1270.0  0.0  0.0     0\n",
       "437  10.0   7.0  1749.0  0.0  0.0     0\n",
       "438  10.0   8.0  2316.0  0.0  0.0     0\n",
       "439  10.0   9.0  2975.0  0.0  0.0     0\n",
       "440  10.0  10.0  3730.0  0.0  0.0     0\n",
       "\n",
       "[441 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h7882 = pd.read_csv('data/hodge/7882.csv', sep=' ', index_col=0)\n",
    "h7882"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
