{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1 - A first look at Neural Networks\n",
    "\n",
    "In this session we implement a fully connected Neural Network by hand. We will only use Numpy to handle the tensors. We do the backpropagation by hand given a cross entropy loss function.\n",
    "\n",
    "All packages used over the next few days can be installed with\n",
    "\n",
    "```console\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "We will train the neural network on the problem of whether a given line bundle has slope zero somewhere in the Kähler cone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NN implementation\n",
    "\n",
    "We recall a Neural Network acts by iteratively applying matrix multiplications with subsequent non linearites:\n",
    "\n",
    "$$\n",
    "z_{i+1} = \\sigma( W_i \\cdot z_{i} + b_i)\n",
    "$$\n",
    "\n",
    "For our initial network we want to study a classification problem with two Classes. Since, this is a classification problem we make use of the softmax activation function in the last layer. Furthermore, we also want to have the option to use the ReLU and sigmoid activation functions in the intermediate layers:\n",
    "\n",
    "$$\n",
    "\\text{softmax} (x_i) = p(x_i) = \\frac{e^{x_i}}{\\sum_i e^{x_i}}.\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\text{relu} (x) = \\begin{cases}\n",
    "x \\text{ if } x > 0 \\\\\n",
    "0 \\text{ else}\n",
    "\\end{cases}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\text{sigmoid} (x) = \\frac{1}{1+e^{-x}}.\n",
    "$$\n",
    "\n",
    "Let's get started by implementing the neural network class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, nInput, nLayer, nClasses, nHidden, activation):\n",
    "        \n",
    "        shapes = [nInput] + [nHidden for _ in range(nLayer)] + [nClasses]\n",
    "        self.b = [np.zeros(shapes[i+1]) for i in range(nLayer+1)]\n",
    "        self.W = [np.zeros((shapes[i], shapes[i+1])) for i in range(nLayer+1)]\n",
    "        self.act = [activation for _ in range(nLayer)] + ['softmax'] \n",
    "        self.nLayer = nLayer+1\n",
    "        self.nClasses = nClasses\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self,mu = 0, sigma = 0.2):\n",
    "        for i in range(self.nLayer):\n",
    "            self.W[i] = np.random.normal(mu, sigma, np.shape(self.W[i]))\n",
    "            self.b[i] = np.random.normal(mu, sigma, np.shape(self.b[i]))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-1*x))\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.where(x > 0, x, 0)\n",
    "    \n",
    "    def forward(self, x, i):\n",
    "        return np.dot(x, self.W[i]) + self.b[i]\n",
    "    \n",
    "    def act_forward(self, x, act):\n",
    "        return act(x)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        # introuce numerical stability\n",
    "        x_stable = x-np.max(x)\n",
    "        e = np.exp(x_stable)\n",
    "        s = np.multiply(e, np.reshape(1/np.sum(e, axis=1), (x.shape[0],1)))\n",
    "        return s\n",
    "    \n",
    "    def activation(self, i):\n",
    "        if self.act[i] == 'relu':\n",
    "            return self.relu\n",
    "        elif self.act[i] == 'sigmoid':\n",
    "            return self.sigmoid\n",
    "        elif self.act[i] == 'softmax':\n",
    "            return self.softmax\n",
    "        \n",
    "    def predict(self, x, train = True):\n",
    "        # zk = regression\n",
    "        zk = []\n",
    "        # ak = act(zk)\n",
    "        ak = [np.copy(x)]\n",
    "        for i in range(len(self.W)):\n",
    "            zk += [self.forward(ak[-1], i)]\n",
    "            ak += [self.act_forward(zk[-1], self.activation(i))]\n",
    "            \n",
    "        pred = ak[-1]\n",
    "            \n",
    "        if train:\n",
    "            return pred, {'zk': zk, 'ak': ak}\n",
    "        else:\n",
    "            return pred\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        z = x\n",
    "        for i in range(self.nLayer):\n",
    "            z = self.act_forward(self.forward(z, i), self.activation(i))\n",
    "        return z.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The optimizer implementation\n",
    "\n",
    "In this section we implement the optimizer. This class will need access to the neural network weights and biases. We further need the derivatives to implement the backpropagation.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{softmax}_j (x)}{\\partial x_k} = \\begin{cases} p_j(x) ( 1- p_k(x)) \\qquad &\\text{for j=k} \\\\\n",
    "- p(x_j) p(x_k) \\qquad \\qquad &\\text{for i $\\neq$ j}\n",
    "\\end{cases}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial \\text{relu} (x)}{\\partial x} = \\begin{cases}\n",
    "1 \\text{ if } x > 0 \\\\\n",
    "0 \\text{ else}\n",
    "\\end{cases}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial \\text{sigmoid} (x)}{\\partial x} = \\text{sigmoid}(x) (1 - \\text{sigmoid}(x)).\n",
    "$$\n",
    "\n",
    "The cross entropy loss for a single datapoint is defined as\n",
    "\n",
    "$$\n",
    "L = - \\sum_j y_j \\log (a_j)\n",
    "$$\n",
    "\n",
    "where $y$ is the true label and $z$ is the predicted probability. Thus, when implementing the backpropagation we arrive at\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial p_j} = p_j - y_j.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optimizer:\n",
    "    def __init__(self, NN, lr):\n",
    "        self.NN = NN\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update_weights(self, dw, db):\n",
    "        for i in range(self.NN.nLayer):\n",
    "            self.NN.W[i] -= self.lr*dw[-1-i]\n",
    "            self.NN.b[i] -= self.lr*db[-1-i]\n",
    "            \n",
    "    def act_backward(self, zk, act):\n",
    "        if act == 'relu':\n",
    "            return self.relu_back(zk)\n",
    "        elif act == 'sigmoid':\n",
    "            return self.sigmoid_back(zk)\n",
    "    \n",
    "    def linear_backward(self, d, i):\n",
    "        return np.dot(d, self.NN.W[i].T)\n",
    "    \n",
    "    def relu_back(self, x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "    \n",
    "    def sigmoid_back(self, x):\n",
    "        s = self.NN.sigmoid(x)\n",
    "        return s*(1-s)\n",
    "        \n",
    "    def partial_theta(self, y, zk, ak):\n",
    "        dw = []\n",
    "        db = []\n",
    "        nSample = y.shape[0]\n",
    "        \n",
    "        #first the cross entropy loss deriv\n",
    "        d = [ak[-1]-y]\n",
    "        # initialize the first dw db derivatives\n",
    "        dw += [np.dot(np.transpose(ak[-2]), d[0])/nSample]\n",
    "        db += [np.sum(d[0], axis=0)/nSample]\n",
    "\n",
    "        #next we loop over all other layers\n",
    "        for i in reversed(range(self.NN.nLayer-1)):\n",
    "            activation = self.act_backward(zk[i], self.NN.act[i])\n",
    "            lb = self.linear_backward(d[self.NN.nLayer-2-i], i+1)\n",
    "            d += [lb*activation]\n",
    "            dw += [np.dot(ak[i].T, d[-1])/nSample]\n",
    "            db += [np.sum(d[-1], axis=0)/nSample]\n",
    "            \n",
    "        return dw, db\n",
    "    \n",
    "    def compute_loss(self, ypred, ytrue, eps=1e-7):\n",
    "        #crossentropy\n",
    "        y_label = ytrue.argmax(axis=1)\n",
    "        loss = (-1)*np.mean(np.log(ypred[range(len(ypred)), y_label]+eps))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training loop\n",
    "\n",
    "We write a training loop that takes as arguments the training and test data, the NN, the optimizer, the (mini) batch size and the number of training Epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(train_data, test_data, NN, optimizer, nEpochs, bSize):\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    x_train, y_train = train_data\n",
    "    x_test, y_test = test_data\n",
    "    steps = int(x_train.shape[0]/bSize)\n",
    "    #t = trange(nEpochs)\n",
    "    for i in range(nEpochs):\n",
    "        shuffled_indices = np.arange(len(x_train))\n",
    "        np.random.shuffle(shuffled_indices)\n",
    "        x_train = x_train[shuffled_indices]\n",
    "        y_train = y_train[shuffled_indices]\n",
    "        for j in range(steps):\n",
    "            x_mini, y_mini = x_train[j*bSize:(j+1)*bSize], y_train[j*bSize:(j+1)*bSize]\n",
    "            y_pred, inter = NN.predict(x_mini)\n",
    "            # next we backpropagate\n",
    "            dw, db = optimizer.partial_theta(y_mini, inter['zk'], inter['ak'])\n",
    "            optimizer.update_weights(dw, db)\n",
    "            train_loss += [optimizer.compute_loss(y_pred, y_mini)]\n",
    "        test_loss += [optimizer.compute_loss(NN.predict(x_test, False), y_test)]\n",
    "        train_accuracy += [np.sum(NN(x_train) == y_train.argmax(axis=-1))/len(x_train)]\n",
    "        test_accuracy += [np.sum(NN(x_test) == y_test.argmax(axis=-1))/len(x_test)]\n",
    "        # t.set_description\n",
    "        print('Epoch {}. Train acc: {}, Test acc: {}.'.format(1+i,\n",
    "                                train_accuracy[-1], test_accuracy[-1]))\n",
    "    loss = {'train_loss': train_loss, 'test_loss': test_loss, \n",
    "            'train_accuracy': train_accuracy, 'test_accuracy': test_accuracy}\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "We want to investigate whether a given line bundle over a CICY is slope stable somewhere in the Kähler cone. This amounts to solving the following constraints:\n",
    "\n",
    "$$\n",
    "\\mu(L) = d_{ijk} q^i t^j t^k = 0 \\qquad \\forall t^j > 0 \\\\\n",
    "$$\n",
    "\n",
    "This question was investigated first in varied form by [Fabian Ruehle](https://arxiv.org/pdf/1706.07024.pdf). Take the bicubic:\n",
    "\n",
    "$$\n",
    "M = \\left[\n",
    "\\begin{array}{c||c}\n",
    "2 & 3\\\\\n",
    "2 & 3\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "which has slope constraint [with some abuse of notation]:\n",
    "$$\n",
    "\\mu(L) = 6m_0t_0t_1 + 3m_0t_1^2 + 3m_1t_0^2 + 6m_1t_0t_1.\n",
    "$$\n",
    "We will generate data using the [pyCICY](https://github.com/robin-schneider/CICY) package for line bundles with charges in the range {-10, ... ,10}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyCICY import CICY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = CICY([[2,3],[2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0*m0*t0*t1 + 3.0*m0*t1**2 + 3.0*m1*t0**2 + 6.0*m1*t0*t1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.line_slope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmax = 10\n",
    "x = np.zeros((2*kmax+1, 2*kmax+1, 2))\n",
    "y = np.zeros((2*kmax+1, 2*kmax+1), dtype=np.int)\n",
    "for i in range(-kmax, kmax+1):\n",
    "    for j in range(-kmax, kmax+1):\n",
    "        x[i,j] = np.array([i,j])\n",
    "        y[i,j] = M.l_slope([i,j])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network\n",
    "\n",
    "Next we want to train the network. First we manipulate the data into a shuffled train and test split. Then, we set some hyperparameters and construct our Neural Network and optimizer. Finally, we train using our custom training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441, 2) (441, 2)\n"
     ]
    }
   ],
   "source": [
    "x = x.reshape((-1, 2))\n",
    "y = y.reshape((-1,1))\n",
    "y = np.eye(2)[y].reshape((-1,2)) #one-hot-encoding\n",
    "print(x.shape, y.shape)\n",
    "shuffled_indices = np.arange(len(x))\n",
    "np.random.shuffle(shuffled_indices)\n",
    "x = x[shuffled_indices]\n",
    "y = y[shuffled_indices]\n",
    "train_indices = int(0.8*len(x))\n",
    "train_data = (x[0:train_indices], y[0:train_indices])\n",
    "test_data = (x[train_indices:], y[train_indices:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nHidden = 64\n",
    "nLayers = 1\n",
    "act = 'relu'\n",
    "lr = 0.001\n",
    "nCharges = 2\n",
    "nClasses = 2\n",
    "nEpoch = 100\n",
    "bSize = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(nCharges, nLayers, nClasses, nHidden, act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizer(model, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_weights = [np.copy(w) for w in model.W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Train acc: 0.3778409090909091, Test acc: 0.4157303370786517.\n",
      "Epoch 2. Train acc: 0.4403409090909091, Test acc: 0.48314606741573035.\n",
      "Epoch 3. Train acc: 0.5170454545454546, Test acc: 0.550561797752809.\n",
      "Epoch 4. Train acc: 0.6107954545454546, Test acc: 0.6404494382022472.\n",
      "Epoch 5. Train acc: 0.7244318181818182, Test acc: 0.7415730337078652.\n",
      "Epoch 6. Train acc: 0.7642045454545454, Test acc: 0.8314606741573034.\n",
      "Epoch 7. Train acc: 0.8039772727272727, Test acc: 0.8426966292134831.\n",
      "Epoch 8. Train acc: 0.8352272727272727, Test acc: 0.8876404494382022.\n",
      "Epoch 9. Train acc: 0.8607954545454546, Test acc: 0.898876404494382.\n",
      "Epoch 10. Train acc: 0.8721590909090909, Test acc: 0.9325842696629213.\n",
      "Epoch 11. Train acc: 0.8892045454545454, Test acc: 0.9325842696629213.\n",
      "Epoch 12. Train acc: 0.8948863636363636, Test acc: 0.9325842696629213.\n",
      "Epoch 13. Train acc: 0.9034090909090909, Test acc: 0.9325842696629213.\n",
      "Epoch 14. Train acc: 0.9090909090909091, Test acc: 0.9438202247191011.\n",
      "Epoch 15. Train acc: 0.9147727272727273, Test acc: 0.9438202247191011.\n",
      "Epoch 16. Train acc: 0.9261363636363636, Test acc: 0.9438202247191011.\n",
      "Epoch 17. Train acc: 0.9289772727272727, Test acc: 0.9438202247191011.\n",
      "Epoch 18. Train acc: 0.9346590909090909, Test acc: 0.9438202247191011.\n",
      "Epoch 19. Train acc: 0.9375, Test acc: 0.9550561797752809.\n",
      "Epoch 20. Train acc: 0.9431818181818182, Test acc: 0.9550561797752809.\n",
      "Epoch 21. Train acc: 0.9460227272727273, Test acc: 0.9550561797752809.\n",
      "Epoch 22. Train acc: 0.9488636363636364, Test acc: 0.9550561797752809.\n",
      "Epoch 23. Train acc: 0.9517045454545454, Test acc: 0.9550561797752809.\n",
      "Epoch 24. Train acc: 0.9545454545454546, Test acc: 0.9550561797752809.\n",
      "Epoch 25. Train acc: 0.9573863636363636, Test acc: 0.9550561797752809.\n",
      "Epoch 26. Train acc: 0.9573863636363636, Test acc: 0.9550561797752809.\n",
      "Epoch 27. Train acc: 0.9602272727272727, Test acc: 0.9550561797752809.\n",
      "Epoch 28. Train acc: 0.9602272727272727, Test acc: 0.9550561797752809.\n",
      "Epoch 29. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 30. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 31. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 32. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 33. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 34. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 35. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 36. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 37. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 38. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 39. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 40. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 41. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 42. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 43. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 44. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 45. Train acc: 0.9602272727272727, Test acc: 0.9662921348314607.\n",
      "Epoch 46. Train acc: 0.9630681818181818, Test acc: 0.9662921348314607.\n",
      "Epoch 47. Train acc: 0.9630681818181818, Test acc: 0.9662921348314607.\n",
      "Epoch 48. Train acc: 0.9630681818181818, Test acc: 0.9662921348314607.\n",
      "Epoch 49. Train acc: 0.9630681818181818, Test acc: 0.9662921348314607.\n",
      "Epoch 50. Train acc: 0.9630681818181818, Test acc: 0.9662921348314607.\n",
      "Epoch 51. Train acc: 0.9630681818181818, Test acc: 0.9662921348314607.\n",
      "Epoch 52. Train acc: 0.9630681818181818, Test acc: 0.9662921348314607.\n",
      "Epoch 53. Train acc: 0.9630681818181818, Test acc: 0.9662921348314607.\n",
      "Epoch 54. Train acc: 0.9630681818181818, Test acc: 0.9662921348314607.\n",
      "Epoch 55. Train acc: 0.9630681818181818, Test acc: 0.9662921348314607.\n",
      "Epoch 56. Train acc: 0.9630681818181818, Test acc: 0.9775280898876404.\n",
      "Epoch 57. Train acc: 0.9659090909090909, Test acc: 0.9775280898876404.\n",
      "Epoch 58. Train acc: 0.9659090909090909, Test acc: 0.9887640449438202.\n",
      "Epoch 59. Train acc: 0.9659090909090909, Test acc: 0.9887640449438202.\n",
      "Epoch 60. Train acc: 0.96875, Test acc: 0.9887640449438202.\n",
      "Epoch 61. Train acc: 0.96875, Test acc: 0.9887640449438202.\n",
      "Epoch 62. Train acc: 0.96875, Test acc: 0.9887640449438202.\n",
      "Epoch 63. Train acc: 0.96875, Test acc: 0.9887640449438202.\n",
      "Epoch 64. Train acc: 0.96875, Test acc: 0.9887640449438202.\n",
      "Epoch 65. Train acc: 0.9715909090909091, Test acc: 0.9887640449438202.\n",
      "Epoch 66. Train acc: 0.9715909090909091, Test acc: 0.9887640449438202.\n",
      "Epoch 67. Train acc: 0.9715909090909091, Test acc: 0.9887640449438202.\n",
      "Epoch 68. Train acc: 0.9715909090909091, Test acc: 0.9887640449438202.\n",
      "Epoch 69. Train acc: 0.9715909090909091, Test acc: 0.9887640449438202.\n",
      "Epoch 70. Train acc: 0.9715909090909091, Test acc: 0.9887640449438202.\n",
      "Epoch 71. Train acc: 0.9715909090909091, Test acc: 0.9887640449438202.\n",
      "Epoch 72. Train acc: 0.9715909090909091, Test acc: 1.0.\n",
      "Epoch 73. Train acc: 0.9744318181818182, Test acc: 1.0.\n",
      "Epoch 74. Train acc: 0.9744318181818182, Test acc: 1.0.\n",
      "Epoch 75. Train acc: 0.9744318181818182, Test acc: 1.0.\n",
      "Epoch 76. Train acc: 0.9772727272727273, Test acc: 1.0.\n",
      "Epoch 77. Train acc: 0.9772727272727273, Test acc: 1.0.\n",
      "Epoch 78. Train acc: 0.9772727272727273, Test acc: 1.0.\n",
      "Epoch 79. Train acc: 0.9772727272727273, Test acc: 1.0.\n",
      "Epoch 80. Train acc: 0.9772727272727273, Test acc: 1.0.\n",
      "Epoch 81. Train acc: 0.9772727272727273, Test acc: 1.0.\n",
      "Epoch 82. Train acc: 0.9772727272727273, Test acc: 1.0.\n",
      "Epoch 83. Train acc: 0.9772727272727273, Test acc: 1.0.\n",
      "Epoch 84. Train acc: 0.9772727272727273, Test acc: 1.0.\n",
      "Epoch 85. Train acc: 0.9772727272727273, Test acc: 1.0.\n",
      "Epoch 86. Train acc: 0.9772727272727273, Test acc: 1.0.\n",
      "Epoch 87. Train acc: 0.9772727272727273, Test acc: 1.0.\n",
      "Epoch 88. Train acc: 0.9801136363636364, Test acc: 1.0.\n",
      "Epoch 89. Train acc: 0.9801136363636364, Test acc: 1.0.\n",
      "Epoch 90. Train acc: 0.9801136363636364, Test acc: 1.0.\n",
      "Epoch 91. Train acc: 0.9801136363636364, Test acc: 1.0.\n",
      "Epoch 92. Train acc: 0.9801136363636364, Test acc: 1.0.\n",
      "Epoch 93. Train acc: 0.9801136363636364, Test acc: 1.0.\n",
      "Epoch 94. Train acc: 0.9801136363636364, Test acc: 1.0.\n",
      "Epoch 95. Train acc: 0.9801136363636364, Test acc: 1.0.\n",
      "Epoch 96. Train acc: 0.9801136363636364, Test acc: 1.0.\n",
      "Epoch 97. Train acc: 0.9801136363636364, Test acc: 1.0.\n",
      "Epoch 98. Train acc: 0.9801136363636364, Test acc: 1.0.\n",
      "Epoch 99. Train acc: 0.9801136363636364, Test acc: 1.0.\n",
      "Epoch 100. Train acc: 0.9801136363636364, Test acc: 1.0.\n"
     ]
    }
   ],
   "source": [
    "stats = training_loop(train_data, test_data, model, opt, nEpoch, bSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a closer look at these results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmUVPWZ//H3Q9PsqECzdrOp7ULUuCDRaBI1LoAJaMzPSHQmOibEnBi3aKIzUaNm8otOxjgmhgxmjEnchjFGiYKgjgT9qQhGVERIt4BSzWIDgrLT9PP743u7KJteqpu+dburPq9z6lTdb92qeu4pqKe/u7k7IiIiAJ2SDkBERNoPJQUREUlTUhARkTQlBRERSVNSEBGRNCUFERFJU1IQEZE0JQUREUlTUhARkbTOSQfQUiUlJT5ixIikwxAR6VBee+21de7ev7nzOlxSGDFiBAsWLEg6DBGRDsXM3svmPDUfiYhImpKCiIikKSmIiEiakoKIiKQpKYiISFpsScHM7jOzD8xsUSPPm5ndbWaVZvammR0bVywiIpKdOGsK9wNjm3h+HFAe3SYDU2KMRUREshDbPAV3n2tmI5o4ZSLwBw/7gb5iZgeY2WB3Xx1XTCISrx074De/gfXrk44kP335y3D88fF+RpKT10qBlRnHqahsr6RgZpMJtQmGDRuWk+BEpGXc4ZvfhAceALOko8lPQ4bkd1Jo6J+NN3Siu08FpgKMHj26wXNEJFm33BISwk9+Av/yL0lHI62V5OijFDA047gMWJVQLCKyD/7wh5AULrkE/vmfk45G9kWSNYXpwOVm9gjwGWCT+hNE9vbyyzBpEmzcmHQkjfvoIzjttNCfoKajji22pGBmDwOnACVmlgJuBooB3P03wAxgPFAJbAUuiSsWkY7q3XdhwgTYbz+4+OKko2ncfvvBNddAly5JRyL7Ks7RR5Oaed6B78b1+SId3YYNcPbZUFsLTz8N5eVJR1RAVqxon1WzsjIoKYn1Izrc0tki+WrbNvjLX2D79nD829/C8uXw3HN5nBBqa+H11+GDD5KOJIyn/etf4amnoKIi6WgaNmUKXHZZrB+hpCDSDuzeDeefD08+uaesUyf44x/h5JOTi2ufrF0Lc+bAli17P1dTAy+9BDNnto+EUKdrVzj1VPje92Do0ObPz7VPfzr2j1BSEGkHrr46JIQ774SJE0NZ797Qv9l9slppwwaYNQuWLWv7996yBZ59FubPb/q8Pn1g7NjQRnbwwW0fR0t16gSjRkHPnklHkiglBZGE/cd/wC9/Cd//fkgOWdm5E+bODT++mzdn/2Hu8MYbYUhTbW2r4m2WGXzmM3DbbeFHf8CAhs8bMgQ66yeovdE3IvvkhRfghhv2tINLy7iHJvVzz4U77ogK3303tGu/9BLs2rX3i7ZuhRdfDMmguDgM/WmJ4cPD7LKzz4Zjjmn7MaRm+rHvwPTNSastWbJnuOSRRyYdzb5y+Ojj0L69fh3U7M7ZJ48ZsJZ/r/olnU7eAevW7enkHDECevXa+wVFRXDhheFH/bTTCr65Q9qWkoI0LZWCGTPCX65vvpku/mB3P8avfowutT34a89zGPF2VYJBtoEtW6C6Ojw++ugYG/MbUxxuAwbA5ZeHH/yDDspxDCJKCnmjsnIfBnHU1MBbb4XmipdegqqMH/hdO8P9wEFw5D9C5844xrULLmCND2TO2J8xouQgoIP/gHXuDJ/9LIwbF9q6RQqUkkIeePhh+PrX9+UdOgPHRLdG5hOujW4RM/jTn2DMuTfvyweLSDujpNDBvfhiWP7gc5+DH/2oiRPdw/DDefPCbckSwKFPXxgzJtyOPRZ69Mjqc8vKwug9EckvSgodWGUlnHNO6I98/HHo27feCZs3h+mwTz4Z+gVWRYvQHn88/Pjs0G597LFhfLaICEoK7ca8eXD33WFma7Zefjk04zz1VEZC2LkTfvc7eOyxMJt0584wC+rMM0MSGDcOBg2K4xJEJA8oKbQDS5eG32pofJ5PQ0pK4Fe/ypgM+vTTcOWV8Pe/w6GH7hnFcvLJWr5SRLKipJCw6moYPz7MQXrlFRg5soVvsGEDPPR02PJq5kw45JDQVFSXZUREWkBJISY1NeH3urlzvvrV0NQ/Z04LE8KcOXDzzaGnubY2jKu//Xa46irVCkSk1ZQUYjJ+PDzzTPPnmcH//E9YKiYrK1fCtdfCtGkwbNie5QqOP14dxiKyz5QUYrB+fRj085WvwBe/2PS5o0bBKac084ZVVXtmFc+aFcpuuQWuuw66d2+LkEVEACWFWMyeHVp0fvCDFtQAGnPvvfDtb4d5BsOGwaWXhmQwfHibxCoikklJIQYzZoSRQaNH7+MbPfMMfOc7cMYZ8O//Dp/6lHZFF5FYKSm0sbr9dM86Kyxm2WqLF4de6FGjQqdDS5dHFhFpBfVMtrEFC8Lqx+PH78ObvP9+6Dzu3j3MRlZCEJEcUVJoYzNnhhaeM89sxYu3b4ef/hQOPzwsefqXv4R+BBGRHIk1KZjZWDNbamaVZnZ9A88PN7PnzOxNM5tjZmVxxpMLM2aEzuWSkha8yD0kgCOOCENMzzoLFi0Kw0xFRHIotqRgZkXAPcA4YBQwyczqr6v5c+AP7n4UcCvwf+OKJxeqq8Ne5S2aTLx0aWhrmjAhTGuePTusW9Tiqc0iIvsuzprCGKDS3Ze5+07gEWBivXNGAc9Fj59v4PkOZdas8Ed/Vv0J7vDzn4d9LF96Ce68M+xsdsYZsccpItKYOJNCKbAy4zgVlWV6Azgvenwu0NvM+sUYU6xmzgwL2h17bDMn7t4N3/1umG8wYUJYwO7qq0NNQUQkQXEmhYYG1Hu942uBL5jZ68AXgCqgZq83MptsZgvMbEF13T667czcuWHk6Je/3MxqE1u3hqnOU6aE2W3TpsHAgTmLU0SkKXEmhRQwNOO4DFiVeYK7r3L3r7j7McC/RGWb6r+Ru09199HuPrp/zjdUb97SpWGzmwMPhH/7tyZOnDkzbAr/5JNhzevbb9d6RSLSrsT5izQfKDezkWbWBbgAmJ55gpmVmFldDDcA98UYTyyqq8OUgs6dw8ijPn0aOGnFilCFGD8+jFedNSs0H4mItDOxJQV3rwEuB2YB7wDT3P1tM7vVzCZEp50CLDWzvwMDgX+NK564TJoEqRQ88USoKexl1y4YOzYsdX3HHfDWW3D66bkOU0QkK7Euc+HuM4AZ9cpuynj8KPBonDHEad26sBrqrbfCiSc2ctKUKaF9afr0UFsQEWnH1KC9D159Ndx//vONnLBhA/z4x6Fm8KUv5SosEZFWU1LYB6+8EvqJjzuukRNuuQU2bQpzELS6qYh0AEoK+2DevLAyRa9eDTy5dCn8+tfwrW+FCWoiIh2AkkIr1daG5qMGN9GpqQmji3r0CB0OIiIdhPZTaKWKCti4sZGkcM01oQf63nvDFGcRkQ5CNYVWmjcv3J9wQr0nfvnLcLvmGvjmN3Mel4jIvlBSaKV586B3bzjssIzCGTPgqqvCekZ33JFYbCIiraWk0Erz5oXtDtJbbu7aBf/0T6FT+cEH93EvThGRZCgptMK2bfDGG/X6E2bOhLVr4bbbGhmOJCLS/ikptMLf/hYGGH0iKfzud2G10xbtsCMi0r4oKbRCXSdzOil88EFY+fQf/iGsjCci0kEpKbTCvHkwbBgMGhQVPPhgqDpcckmicYmI7CslhRZyD8tbpIeiuoemozFjYFT9LahFRDoWJYUWuu02eP/9sBo2EDoY3noLLr44ybBERNqEkkILPPAA3HwzfOMbGTng/vuha1e44IIEIxMRaRtKClmaOxcuvRROOQWmTo0WPa2pgYcfhnPPbWTLNRGRjkVJIQtbt8JXvgIjR8Jjj0GXLtETL7wA69fD+ecnGp+ISFvR+MksLF8efvvvvrteheCJJ6BbNzjzzMRiExFpS6opZCGVCvfDhmUUusPjj4dd1Xr2TCQuEZG2pqSQhbqkUFqaUfjmm/Dee3DOOYnEJCISByWFLFRVhfshQzIKn3gi9DZr72URySNKCllIpaB//zDyNO3xx+HEE8N6RyIieUJJIQtVVVBWllHw/vvw+utqOhKRvBNrUjCzsWa21Mwqzez6Bp4fZmbPm9nrZvammY2PM57WSqXqJYXp08P9xImJxCMiEpfYkoKZFQH3AOOAUcAkM6u/ONCPgGnufgxwAfDruOLZF1VV9TqZn3gibLl2yCGJxSQiEoc4awpjgEp3X+buO4FHgPp/WjuwX/R4f2BVjPG0yrZtYY5CuqaweTPMmRO23BQRyTNxTl4rBVZmHKeAz9Q758fAbDP7HtATOD3GeFplVZSm0jWFl14Ky1uc3u5CFRHZZ3HWFKyBMq93PAm4393LgPHAH81sr5jMbLKZLTCzBdXV1TGE2ri6OQrpmsLcuWH/5RNPzGkcIiK5EGdSSAFDM47L2Lt56FJgGoC7vwx0A0rqv5G7T3X30e4+un///jGF27AGk8Jxx2kfZhHJS3EmhflAuZmNNLMuhI7k6fXOeR/4IoCZHU5ICrmtCjSjbuJaaSmhg2HePPj85xONSUQkLrElBXevAS4HZgHvEEYZvW1mt5pZXS/t94FvmdkbwMPAxe5ev4kpUakU7Lcf9O4NvPoq7NwJX/hC0mGJiMQi1lVS3X0GMKNe2U0ZjxcDJ8UZw776xHDUuXPD0hYnteuQRURaTTOam/GJiWtz58JRR2lDHRHJW0oKzUjXFHbtCsNR1Z8gInlMSaEJNTWwenVUU3jttbAFm5KCiOQxJYUmrF0LtbVRUpg7NxQqKYhIHlNSaMInNteZOzesdzRgQKIxiYjESUmhCemJa4N3w4svqpYgInlPSaEJ6YlrmxbDpk1KCiKS95QUmpBKQZcuUPLm/4YCJQURyXNKCk2oG45qL8yFkSNh6NDmXyQi0oE1mxTM7HIzK8jZWmHimodOZtUSRKQAZFNTGATMN7Np0faaDS2JnZeqqqCs90ewbp3WOxKRgtBsUnD3HwHlwH8BFwMVZvZTMzso5tgS5R5qCqU7l4cC1RREpABk1acQrVy6JrrVAH2AR83sjhhjS9SGDbBjB5RteBOGDIEDD0w6JBGR2DW7SqqZXQF8A1gH/Ba4zt13RTukVQA/iDfEZNQNRx2y/P/B2C+E1VFFRPJcNktnlwBfcff3MgvdvdbMvhRPWMlbvTrcD/lwEXz+H5INRkQkR7JpPpoBbKg7MLPeZvYZAHd/J67AkrZmTbgfxBr1J4hIwcgmKUwBNmccb4nK8lpdTWFQvxo4/PBkgxERyZFskoJlbpHp7rXEvGNbe7BmDfS2j+n5hdHqTxCRgpFNUlhmZleYWXF0uxJYFndgSVu9bBuDfRV87nNJhyIikjPZJIXLgM8CVUAK+AwwOc6g2oM1K3eF/oTDDks6FBGRnGm2GcjdPwAuyEEs7crqDzpxLKthwCFJhyIikjPZzFPoBlwKfAroVlfu7v8UY1yJW7OhS6gpDDg56VBERHImm+ajPxLWPzoL+CtQBnwcZ1BJ27IFPt7ehcGshv79kw5HRCRnskkKB7v7jcAWd/89cDZwZDZvHi2gt9TMKs3s+gae/4WZLYxufzezjS0LPx7pOQrdNkHXrskGIyKSQ9kMLd0V3W80syMI6x+NaO5FZlYE3AOcQeignm9m0919cd057n51xvnfA47JPvT41M1RGNx3R7KBiIjkWDY1hanRfgo/AqYDi4Hbs3jdGKDS3Ze5+07gEWBiE+dPAh7O4n1jl64p9N+dbCAiIjnWZE0hWvTuI3f/EJgLtGSp0FJgZcZx3XDWhj5nODAS+N8WvH9s0jWFIZq0JiKFpcmaQjR7+fJWvndDv6jeQBmEIa+PunuDf5qb2WQzW2BmC6qrq1sZTvbWrIEiauhX2q35k0VE8kg2zUfPmNm1ZjbUzPrW3bJ4XQrI3NS4DFjVyLkX0ETTkbtPdffR7j66fw5GA61e5QxkLZ0GauSRiBSWbDqa6+YjfDejzGm+KWk+UG5mIwmzoS8Avl7/JDM7lLBpz8tZxJITa1K7wnDUAQOSDkVEJKeymdE8sjVv7O41ZnY5MAsoAu5z97fN7FZggbtPj06dBDySuehe0lanailljZKCiBScbGY0/2ND5e7+h+Ze6+4zCPsxZJbdVO/4x829T66t+cAYzWoYkNfbUIuI7CWb5qPjMx53A74I/A1oNil0RLt3wwcfRktc9D8h6XBERHIqm+aj72Uem9n+hKUv8lJ1NdS6qU9BRApSNqOP6tsKlLd1IO1Fesc11kK/fskGIyKSY9n0KfyFPfMLOgGjgGlxBpWkutnMg/ffCp3zfoM5EZFPyOZX7+cZj2uA99w9FVM8iUvXFLTEhYgUoGySwvvAanffDmBm3c1shLuviDWyhKTXPRqUbBwiIknIpk/hf4DajOPdUVleWr0a9u/0Ed0HH5B0KCIiOZdNUugcrXIKQPS4S3whJWvNGhisiWsiUqCySQrVZjah7sDMJgLr4gspWatX1TKotkpJQUQKUjZ9CpcBD5rZr6LjFNDgLOd8sGZVLWM0R0FEClQ2k9feBU4ws16AuXve7s/sDqvXWDSbeXjS4YiI5FyzzUdm9lMzO8DdN7v7x2bWx8x+kovgcm3zZti6vUizmUWkYGXTpzDO3TfWHUS7sI2PL6Tk7JnNrI5mESlM2SSFIjPrWndgZt2Brk2c32Glt+FUTUFEClQ2Hc0PAM+Z2e+i40uA38cXUnKqqsJ9adFaOEDzFESk8GTT0XyHmb0JnE7Yd/lpIC97YeuSQlnJdrCGtpgWEclv2a6SuoYwq/k8wn4K78QWUYJSKejdeSu9B/VMOhQRkUQ0WlMws0MI+ypPAtYD/00YknpqjmLLuaoqKCteq/4EESlYTTUfLQFeAL7s7pUAZnZ1TqJKSCoFpWg2s4gUrqaaj84jNBs9b2b3mtkXCX0KeSuVgrJdK5QURKRgNZoU3P3P7v414DBgDnA1MNDMppjZmTmKL2dqamDNGqesZjn07590OCIiiWi2o9ndt7j7g+7+JaAMWAhcH3tkObZ2LezebWo+EpGC1qI9mt19g7v/p7ufFldASUkPRyWlmoKIFKwWJYWWMrOxZrbUzCrNrMHahZmdb2aLzextM3sozniakoo2GC2lCgYPTioMEZFExbYzvZkVAfcAZxCW255vZtPdfXHGOeXADcBJ7v6hmSXWbvOJmkJpaVJhiIgkKs6awhig0t2XRbu1PQJMrHfOt4B7okX2cPcPYoynSakUdCmqocQ2qE9BRApWnEmhFFiZcZyKyjIdAhxiZv/PzF4xs7ENvZGZTTazBWa2oLq6OpZgq6qgtPuH2KCB0Dm2CpSISLsWZ1JoaE6D1zvuDJQDpxBmTv/WzPZaic7dp7r7aHcf3T+mTuBUCkqL16rpSEQKWpxJIQUMzTguA1Y1cM4T7r7L3ZcDSwlJIueqqqCsdiUMGZLEx4uItAtxJoX5QLmZjTSzLoR1lKbXO+dx4FQAMyshNCctizGmBrlHNYUdy1RTEJGCFltScPca4HJgFmFV1Wnu/raZ3WpmE6LTZgHrzWwx8DxwnbuvjyumxmzYANu3Q9n2CtUURKSgxdqj6u4zgBn1ym7KeOzANdEtMenNdaiCIUclGYqISKJinbzWUdRNXNMcBREpdEoK1Ju4puYjESlgSgqEmoKZM4g1qimISEHTLC1CTWFQj48orimCPn2SDkdEJDFKCkTDUbuug4GlYHm9j5CISJPUfEQ0ca3TKvUniEjBU1Igqinsek9JQUQKXsE3H23ZAhs3Qlnx39XJLCIFr+BrCumJa7uWq6YgIgVPSUGb64iIpBV8Uli+PNwP433VFESk4BV8UqiogM5FtQxHHc0iIkoKFXBgnw/pzG4lBREpeAU/+qiiAsp7roZd+0PPnkmHIyKSqIKuKbhDZSWUFy9XJ7OICAWeFFavhq1b4eBdS9R0JCJCgSeFiopwX751oZKCiAhKCgCUb3hVzUciIhR4UqishOJiZ9juZaopiIhQ4EmhogIOHLKDImpVUxARQUmB8gEbw4FqCiIihZsUamuj4ai91oSC4cOTDUhEpB2INSmY2VgzW2pmlWZ2fQPPX2xm1Wa2MLp9M854Mq1eDdu2QXmnd6FbNxg4MFcfLSLSbsU2o9nMioB7gDOAFDDfzKa7++J6p/63u18eVxyNSY882rEo1BK0DaeISKw1hTFApbsvc/edwCPAxBg/r0XqksLBGxfAyJHJBiMi0k7EmRRKgZUZx6morL7zzOxNM3vUzIbGGM8nVFRAly4wtOoVGDEiVx8rItKuxZkUGmqP8XrHfwFGuPtRwLPA7xt8I7PJZrbAzBZUV1e3SXAVFXDQyN0UfbhOSUFEJBJnUkgBmX/5lwGrMk9w9/XuviM6vBc4rqE3cvep7j7a3Uf379+/TYKrrITywVvCgZqPRESAeJPCfKDczEaaWRfgAmB65glmNjjjcALwTozxpNUNRz14/6jWoZqCiAgQ4+gjd68xs8uBWUARcJ+7v21mtwIL3H06cIWZTQBqgA3AxXHFk6mqCrZvh/Iu74UCJQURESDmTXbcfQYwo17ZTRmPbwBuiDOGhqSHo9YuhR49oI2apEREOrqCnNFcWRnuD968MNQSNEdBRAQo0KRQUQFdu8LQNfPVdCQikqFgk8JBB0Gn95Zr5JGISIaCTAqVlVA+Yhds3KiagohIhoJLCrW18O67UF7yYShQUhARSSu4pJBKheGoB/eI5tEpKYiIpMU6JLU9Sg9H7RQNQVKfgkhB2LVrF6lUiu3btycdSqy6detGWVkZxcXFrXp9wSWFuuGo5dsXQa9e0LdvsgGJSE6kUil69+7NiBEjsDwdhu7urF+/nlQqxchW/sFbcM1HFRVhT53Sas1RECkk27dvp1+/fnmbEADMjH79+u1Tbaggk4KGo4oUpnxOCHX29RoLMimUlzusWKFOZhHJmY0bN/LrX/+6xa8bP348GzdujCGihhVUUti9OxqOOnQHfPSRkoKI5ExjSWH37t1Nvm7GjBkccMABcYW1l4LqaE6lYOdOOHi/taFAzUcikiPXX3897777LkcffTTFxcX06tWLwYMHs3DhQhYvXsw555zDypUr2b59O1deeSWTJ08GYMSIESxYsIDNmzczbtw4Tj75ZF566SVKS0t54okn6N69e5vGWVBJIT0ctVhLZosUtKuugoUL2/Y9jz4a7rqr0ad/9rOfsWjRIhYuXMicOXM4++yzWbRoUXqU0H333Uffvn3Ztm0bxx9/POeddx79+vX7xHtUVFTw8MMPc++993L++efzpz/9iYsuuqhNL6OgkkJ6OOqOReHBgQcmF4yIFLQxY8Z8Ytjo3XffzZ///GcAVq5cSUVFxV5JYeTIkRx99NEAHHfccaxYsaLN4yqopFBRAd27w5DVr8GgQbD//kmHJCJJaOIv+lzp2bNn+vGcOXN49tlnefnll+nRowennHJKg8NKu3btmn5cVFTEtm3b2jyugupoTg9HXfoOHHZY0uGISAHp3bs3H3/8cYPPbdq0iT59+tCjRw+WLFnCK6+8kuPo9ii4msLhhzvMWQJf+1rS4YhIAenXrx8nnXQSRxxxBN27d2fgwIHp58aOHctvfvMbjjrqKA499FBOOOGExOIsmKSwezcsWwYTTt8GH34Ihx6adEgiUmAeeuihBsu7du3KzJkzG3yurt+gpKSERYsWpcuvvfbaNo8PCqj5aOXKMBy1vEcqFKj5SERkLwWTFOqGox5cGz1QTUFEZC8FlxTKP3otrIg3bFiyAYmItEMFkxSGD4dJk2BI1Xw45BAoKko6JBGRdifWpGBmY81sqZlVmtn1TZz3VTNzMxsdVyxnnw0PPQS2dImajkREGhFbUjCzIuAeYBwwCphkZqMaOK83cAUwL65Y0nbsCEOQ1MksItKgOGsKY4BKd1/m7juBR4CJDZx3G3AHEP8eee++C7W1SgoiknOtXTob4K677mLr1q1tHFHD4kwKpcDKjONUVJZmZscAQ939yRjj2GPJknCv5iMRybGOkhTinLzW0PY/nn7SrBPwC+DiZt/IbDIwGWDYvowaUlIQkYRkLp19xhlnMGDAAKZNm8aOHTs499xzueWWW9iyZQvnn38+qVSK3bt3c+ONN7J27VpWrVrFqaeeSklJCc8//3ysccaZFFLA0IzjMmBVxnFv4AhgTrR93CBguplNcPcFmW/k7lOBqQCjR492WmvpUigrg169Wv0WItLxJbBy9ieWzp49ezaPPvoor776Ku7OhAkTmDt3LtXV1QwZMoSnnnoKCGsi7b///tx55508//zzlJSUtG3QDYiz+Wg+UG5mI82sC3ABML3uSXff5O4l7j7C3UcArwB7JYQ2tUQjj0QkebNnz2b27Nkcc8wxHHvssSxZsoSKigqOPPJInn32WX74wx/ywgsvsH8CKznHVlNw9xozuxyYBRQB97n722Z2K7DA3ac3/Q5tHlCoKbTxhhQi0vEkvXK2u3PDDTfw7W9/e6/nXnvtNWbMmMENN9zAmWeeyU033ZTT2GJdEM/dZwAz6pU1eIXufkqcsbB2LWzapJFHIpKIzKWzzzrrLG688UYuvPBCevXqRVVVFcXFxdTU1NC3b18uuugievXqxf333/+J1+ai+ahgVklVJ7OIJClz6exx48bx9a9/nRNPPBGAXr168cADD1BZWcl1111Hp06dKC4uZsqUKQBMnjyZcePGMXjw4Ng7ms299f22SRg9erQvWNCKbof//E+47DJ4/30YOrT580Ukr7zzzjscfvjhSYeREw1dq5m95u7NrhpRMGsfMWgQTJwIpaXNnysiUqAKp/lo4sRwExGRRhVOTUFERJqlpCAiBaOj9aG2xr5eo5KCiBSEbt26sX79+rxODO7O+vXr6datW6vfo3D6FESkoJWVlZFKpaiurk46lFh169aNsrKyVr9eSUFECkJxcTEjR45MOox2T81HIiKSpqQgIiJpSgoiIpLW4Za5MLNq4L0WvKQEWBdTOO1ZIV53IV4zFOZ1F+I1w75d93B379/cSR0uKbSUmS3IZr2PfFOI112I1wyFed2FeM2Qm+sNu9/JAAAFhklEQVRW85GIiKQpKYiISFohJIWpSQeQkEK87kK8ZijM6y7Ea4YcXHfe9ymIiEj2CqGmICIiWcrrpGBmY81sqZlVmtn1SccTBzMbambPm9k7Zva2mV0Zlfc1s2fMrCK675N0rG3NzIrM7HUzezI6Hmlm86Jr/m8z65J0jG3NzA4ws0fNbEn0nZ9YIN/11dG/70Vm9rCZdcu379vM7jOzD8xsUUZZg9+tBXdHv21vmtmxbRVH3iYFMysC7gHGAaOASWY2KtmoYlEDfN/dDwdOAL4bXef1wHPuXg48Fx3nmyuBdzKObwd+EV3zh8CliUQVr/8Annb3w4BPE64/r79rMysFrgBGu/sRQBFwAfn3fd8PjK1X1th3Ow4oj26TgSltFUTeJgVgDFDp7svcfSfwCJB3W6+5+2p3/1v0+GPCj0Qp4Vp/H532e+CcZCKMh5mVAWcDv42ODTgNeDQ6JR+veT/g88B/Abj7TnffSJ5/15HOQHcz6wz0AFaTZ9+3u88FNtQrbuy7nQj8wYNXgAPMbHBbxJHPSaEUWJlxnIrK8paZjQCOAeYBA919NYTEAQxILrJY3AX8AKiNjvsBG929JjrOx+/7QKAa+F3UbPZbM+tJnn/X7l4F/Bx4n5AMNgGvkf/fNzT+3cb2+5bPScEaKMvboVZm1gv4E3CVu3+UdDxxMrMvAR+4+2uZxQ2cmm/fd2fgWGCKux8DbCHPmooaErWjTwRGAkOAnoTmk/ry7ftuSmz/3vM5KaSAoRnHZcCqhGKJlZkVExLCg+7+WFS8tq46Gd1/kFR8MTgJmGBmKwjNgqcRag4HRM0LkJ/fdwpIufu86PhRQpLI5+8a4HRgubtXu/su4DHgs+T/9w2Nf7ex/b7lc1KYD5RHIxS6EDqmpiccU5uL2tL/C3jH3e/MeGo68I3o8TeAJ3IdW1zc/QZ3L3P3EYTv9X/d/ULgeeCr0Wl5dc0A7r4GWGlmh0ZFXwQWk8ffdeR94AQz6xH9e6+77rz+viONfbfTgX+MRiGdAGyqa2baV3k9ec3MxhP+giwC7nP3f004pDZnZicDLwBvsad9/Z8J/QrTgGGE/1T/x93rd2J1eGZ2CnCtu3/JzA4k1Bz6Aq8DF7n7jiTja2tmdjShc70LsAy4hPDHXV5/12Z2C/A1wmi714FvEtrQ8+b7NrOHgVMIK6GuBW4GHqeB7zZKjr8ijFbaClzi7gvaJI58TgoiItIy+dx8JCIiLaSkICIiaUoKIiKSpqQgIiJpSgoiIpKmpCASMbPdZrYw49Zms4XNbETm6pci7VXn5k8RKRjb3P3opIMQSZJqCiLNMLMVZna7mb0a3Q6Oyoeb2XPRevbPmdmwqHygmf3ZzN6Ibp+N3qrIzO6N9gWYbWbdo/OvMLPF0fs8ktBligBKCiKZutdrPvpaxnMfufsYwizSu6KyXxGWLz4KeBC4Oyq/G/iru3+asDbR21F5OXCPu38K2AicF5VfDxwTvc9lcV2cSDY0o1kkYmab3b1XA+UrgNPcfVm0+OAad+9nZuuAwe6+Kypf7e4lZlYNlGUuuRAta/5MtFkKZvZDoNjdf2JmTwObCUsaPO7um2O+VJFGqaYgkh1v5HFj5zQkc12e3ezp0zubsEvgccBrGSt/iuSckoJIdr6Wcf9y9PglwiqtABcCL0aPnwO+A+l9pPdr7E3NrBMw1N2fJ2wadACwV21FJFf0F4nIHt3NbGHG8dPuXjcstauZzSP8ITUpKrsCuM/MriPsiHZJVH4lMNXMLiXUCL5D2DGsIUXAA2a2P2HjlF9EW2yKJEJ9CiLNiPoURrv7uqRjEYmbmo9ERCRNNQUREUlTTUFERNKUFEREJE1JQURE0pQUREQkTUlBRETSlBRERCTt/wOyVIhzGIZH7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd9fdd3ae10>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(stats['train_accuracy']))+1, stats['train_accuracy'], color='red', label='train')\n",
    "plt.plot(np.arange(len(stats['test_accuracy']))+1, stats['test_accuracy'], color='blue', label='test')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl4VNX5wPHvG7aENUACIiCLyiY7iIBWERUBrVqtKIor/VG1KnWrUhW3qlSsRatirUXFDfeliAVRrFUWDRYQBWRTCAiELexbcn5/nLkzd2buLAm5mSTzfp7nPnO3mTk3M7nvnF2MMSillFIAGalOgFJKqYpDg4JSSqkgDQpKKaWCNCgopZQK0qCglFIqSIOCUkqpIA0KSimlgjQoKKWUCtKgoJRSKqh6qhNQUjk5OaZ169apToZSSlUq8+fP32yMyU10XqULCq1btyYvLy/VyVBKqUpFRH5K5jwtPlJKKRWkQUEppVSQBgWllFJBla5OQSmlSuPgwYPk5+ezb9++VCfFV5mZmbRo0YIaNWqU6vkaFJRSaSE/P5969erRunVrRCTVyfGFMYYtW7aQn59PmzZtSvUaWnyklEoL+/bto3HjxlU2IACICI0bNz6s3JAGBaVU2qjKAcFxuNeYXkHhrbdg8+ZUp0IppSqs9AkKGzfChRfCeeelOiVKqTS0fft2nn766RI/b+jQoWzfvt2HFHlLn6Bw4IB9/CmpTn1KKVWmYgWFoqKiuM+bNm0a2dnZfiUrirY+UkqpcnDHHXewcuVKunfvTo0aNahbty7NmjVjwYIFfP/995x33nmsXbuWffv2MXr0aEaNGgWEhvbZtWsXQ4YM4aSTTmL27Nk0b96c999/n6ysrDJNpwYFpVT6+f3vYcGCsn3N7t1hwoSYh8eNG8fixYtZsGABn332GWeddRaLFy8ONh2dNGkSjRo1Yu/evRx//PFccMEFNG7cOOw1li9fzmuvvcY//vEPhg0bxttvv82IESPK9DI0KCilVAr06dMnrC/BE088wbvvvgvA2rVrWb58eVRQaNOmDd27dwegV69e/Pjjj2WeLg0KSqn0E+cXfXmpU6dOcP2zzz5j5syZzJkzh9q1azNgwADPvga1atUKrlerVo29e/eWebrSp6JZKaVSqF69euzcudPzWGFhIQ0bNqR27dosXbqUuXPnlnPqQtInp2BMqlOglEpjjRs35sQTT6Rz585kZWXRtGnT4LHBgwfzzDPP0LVrV9q3b0/fvn1Tls70Cwpp0KNRKVUxvfrqq577a9WqxUcffeR5zKk3yMnJYfHixcH9t956a5mnD9Kx+EiDglJKxZR+QUEppVRMGhSUUkoFaVBQSikVpEFBKaVUkAYFpZRSQb4FBRGZJCKbRGRxjOOXisiiwDJbRLr5lRallEq10g6dDTBhwgT27NlTxiny5mdO4QVgcJzjq4FTjDFdgQeAZ31Mi3ZeU0qlVGUJCr51XjPGfC4ireMcn+3anAu08CstgTf09eWVUioe99DZZ5xxBk2aNOGNN95g//79/OpXv+K+++5j9+7dDBs2jPz8fIqKirj77rvZuHEj69ev59RTTyUnJ4dZs2b5ms6K0qN5JODdnQ8QkVHAKICjjjqqdO+gPZqVUgEpGDk7bOjsGTNm8NZbb/HVV19hjOGcc87h888/p6CggCOPPJIPP/wQsGMiNWjQgMcee4xZs2aRk5NTton2kPKKZhE5FRsUbo91jjHmWWNMb2NM79zc3NK9keYUlFIVxIwZM5gxYwY9evSgZ8+eLF26lOXLl9OlSxdmzpzJ7bffzn//+18aNGhQ7mlLaU5BRLoCzwFDjDFbfH0zDQpKqYBUj5xtjGHMmDH89re/jTo2f/58pk2bxpgxYxg0aBBjx44t17SlLKcgIkcB7wCXGWN+8P0NNSgopVLIPXT2mWeeyaRJk9i1axcA69atY9OmTaxfv57atWszYsQIbr31Vr755puo5/rNt5yCiLwGDAByRCQfuAeoAWCMeQYYCzQGnhZbzn/IGNPbr/RoUFBKpZJ76OwhQ4ZwySWX0K9fPwDq1q3Lyy+/zIoVK7jtttvIyMigRo0aTJw4EYBRo0YxZMgQmjVr5ntFs5hKdrPs3bu3ycvLK/kTly2DDh2gVSvwYQo7pVTFtmTJEjp27JjqZJQLr2sVkfnJ/PBOeUVzualkwU8ppVJBg4JSSqkgDQpKqbRR2YrLS+NwrzH9goJ2XlMqLWVmZrJly5YqHRiMMWzZsoXMzMxSv0ZF6dHsP+eLUFwM994L11wDRxyR0iQppcpPixYtyM/Pp6CgINVJ8VVmZiYtWpR+1KD0Cwpr1sB990FeHkydmto0KaXKTY0aNWjTpk2qk1HhpV/xkaOoKDXpUEqpCix9g0JWVmrSoZRSFVj6BoXDqIhRSqmqKn2DguYUlFIqigYFpZRSQRoUlFJKBaVvUKhRIzXpUEqpCix9g4JSSqko6RsUdLgLpZSKkr5BQSmlVBQNCkoppYLSNyho8ZFSSkVJ36CglFIqSvoEheLi8G3NKSilVJT0CQqaU1BKqYTSNyhoTkEppaKkb1BQSikVxbegICKTRGSTiCyOcVxE5AkRWSEii0Skp19pATQoKKVUEvzMKbwADI5zfAhwbGAZBUz0MS1afKSUUknwLSgYYz4HtsY55VxgsrHmAtki0syv9EQFBc05KKVUlFTWKTQH1rq28wP7oojIKBHJE5G8goKC0r2bBgWllEoolUHBq/zG805tjHnWGNPbGNM7Nze3dO8WGQQi+y0opZRKaVDIB1q6tlsA6317N80pKKVUQqkMCh8AlwdaIfUFCo0xP/v2bppTUEqphKr79cIi8howAMgRkXzgHqAGgDHmGWAaMBRYAewBrvIrLdg3jb+tlFLKv6BgjBme4LgBfufX+3u8Yfh2cTEcOADVqtlFKaVUGvdoLi6GWrWgenUoKkpNmpRSqoJJ36Dg3p4+vXzTopRSFVT6BgV3RfPeveWbFqWUqqDSNyi4tw8eLN+0KKVUBZW+QcGdUxg+HNb710VCKaUqi/QNCpHbzz5bfmlRSqkKKn2DQmTnNW2WqpRSaRwUtm8P39agoJRSaRwUXnstfFuDglJKpXFQiKRBQSmlNCgEaVBQSikNCkEaFJRSSoNCUEb6/CmUUiqW9LkTak5BKaUSSp+gcPrp8Y9rUFBKqTQKCo0axT+uQUEppdIoKLgdc0z0Pg0KSimVpkHBq1JZK5qVUipNg4LX/AkaFJRSKk2Dwtq10fsStU5SSqk0kJ5BwW34cPsYOWqqUkqlobQNCgepTjECtWvbHRoUlFIqPYPCVM6iDrv5nk6hVkdafKSUUv4GBREZLCLLRGSFiNzhcfwoEZklIv8TkUUiMtTP9Dha8yMHqckiuoaCguYUlFLKv6AgItWAp4AhQCdguIh0ijjtLuANY0wP4GLgab/SA9h5mDdupD3LqMEBGxSqV7fHNCgopZSvOYU+wApjzCpjzAFgCnBuxDkGqB9YbwCs9zE90KwZNGlCDQ7Rie/DcwovvODrWyulVGXgZ1BoDrjbfuYH9rndC4wQkXxgGnCD1wuJyCgRyRORvIKCgjJJXFcWhQeFOXNg+XK7/ve/wzvvlMn7KKVUZeJnUBCPfZG1ucOBF4wxLYChwEsiEpUmY8yzxpjexpjeubm5ZZK4rixiHS3YcqBeaKfTqe2aa+CCC8rkfZRSqjLxMyjkAy1d2y2ILh4aCbwBYIyZA2QCOT6mKagriwD4dnOz0E5tgaSUSnN+BoWvgWNFpI2I1MRWJH8Qcc4a4DQAEemIDQplUz6UgBMUFhU0S3CmUkqlD9+CgjHmEHA9MB1Ygm1l9J2I3C8i5wROuwX4PxFZCLwGXGlM+fxcb8pGctnEok1HhHYWFWkrJKVUWqvu54sbY6ZhK5Dd+8a61r8HTvQzDbEIgcrmgvahnb16QfPIunCllEofadmj2dGVRSwuaEqR+8+wbl3qEqSUUimW9kFh76GarOToVCdFKaUqhLQPCoDtr6CUUiq9g0InvidDijUoKKVUQFJBQURGi0h9sf4pIt+IyCC/E+e3TPbTvlEBC+mW6qQopVSFkGxO4WpjzA5gEJALXAWM8y1V5ahrkw2aU1BKqYBkg4IzZMVQ4HljzEK8h7GoHF56KbjaNXcDP9KGwuC4fEoplb6SDQrzRWQGNihMF5F6QOXt5dUtVFzUNceOvKG5BaWUSj4ojATuAI43xuwBamCLkConCWVyjm+6BoB5nJCq1CilVIWRbFDoBywzxmwXkRHYyXEK/UuWz1xBoWntnbRlJbPpn8IEKaVUxZBsUJgI7BGRbsAfgJ+Ayb6lym8ZrssuKqL/wCzm0C9qXG+llEo3yQaFQ4GB6s4FHjfGPA7US/CcisuVU6C4mP4XNGMDzfiR1ilLklJKVQTJBoWdIjIGuAz4MDD/cg3/kuUzd07BGPqfaIOEFiEppdJdskHhImA/tr/CBuy0muN9S5XfInIKnTtDXXZqUFBKpb2kgkIgELwCNBCRs4F9xpiqUadQXEy1atCXuRoUlFJpL9lhLoYBXwEXAsOAeSLyaz8T5it3TiEwp08/5rCIruyiTooSpZRSqZfsJDt3YvsobAIQkVxgJvCWXwnzVUROAaA/symmGl/Rh4HMSlHClFIqtZKtU8hwAkLAlhI8t+Jx5xSKigDo23EHEKeyubAwmKtQSqmqKtkb+79FZLqIXCkiVwIfEjHNZqUSUdEMkH3WiRzHYu+gsGYNZGfDE0+UUwKVUio1kq1ovg14FugKdAOeNcbc7mfCfBXRJNV57M9s5tKXYmesv927YdMm+O47uz2t8sZBpZRKRtJFQMaYt40xNxtjbjLGvOtnonznkVNwgsI2GrGM9nZfr17QtCnssEVL1NeRVJVSVVvcimYR2Qmeoz8IYIwxlfMu6c4pNGhgH4uLOYkvAPiE0+jIUli2zB5bt84+1qu8nbiVUioZcXMKxph6xpj6Hku9ShsQIDyn8PDD9tEYjmElx7CcjxgSfv4tt9jHunXLJ31KKZUivrYgEpHBIrJMRFaIyB0xzhkmIt+LyHci8qqf6QlycgpZWVAn0C8hULcwlGl8ykD2khn9vOrJtuBVSqnKybegEBgf6SlgCNAJGC4inSLOORYYA5xojDkO+L1f6YlIXPQ+V1DYRxafMSD6nGrV/E2XUkqlmJ85hT7ACmPMKmPMAWAKdpRVt/8DnjLGbAOI6AvhHyen4O53EKhwPoX/kMWe6CIk9/OUUqqK8vMu1xxY69rOD+xzawe0E5EvRWSuiAz2eiERGSUieSKSV1BQcPgpi5NTyMzK4DQ+4UPOiq5h185rSqkqzs+g4HHnjbrPVgeOBQYAw4HnRCQ76knGPGuM6W2M6Z2bm1sGKYsdFHj4YYY0mMMqjmY5x4af89ZbsH794b+/UkpVUH4GhXygpWu7BRB5R80H3jfGHDTGrAaWQeSd2AdexUBOUKhRgyE9NwIwjaHh56xeDc2bw6FDPidQKaVSw8+g8DVwrIi0EZGawMXABxHnvAecCiAiOdjipFU+psnyyik4ndgyMmhTcx0d+T46KDgeeMC/tCmlVAr5FhSMMYeA64HpwBLgDWPMdyJyv4icEzhtOrBFRL4HZgG3GWO2+JWmIK+KZmddBA4dYijT+A+neA+lvXKl70lUSqlU8LU5jTFmmjGmnTHmaGPMg4F9Y40xHwTWTWDojE7GmC7GmCl+picoXp2CKygcoBYfc0Zyz1dKqSogPdtYxqtTADh0iF/wX3LZxCtcGn2uBgWlVBWVnkEhXk4hIwMOHaIGh7iUV/gXv2QrDcPPfeklOw/DypWhugillKoC0jMoOGLVKfTtC8AVvMgBavE6F0U/9/HH4Zhj4MEHyyGhSilVPtIzKHjlFI4/3j62bw/jxwPQjYV0YREvckX0+atX28exY+HgQZ8SqpRS5Ss9g4IzsN2NN4b2XXMNLFkCJ50ENWpAr14INrcwj74so13s15s82dfkKqVUeUnPoFCtmq0LeOSR0D4R6NAhtB2YO+ESXiWDIiZzeezXK4uhN5RSqgJIz6AANgjEa0W0axcAzdjAmUznpaa3hqbpBNi3L7T+2Wc6LpJSqkpI36CQSP/+wdXLj53L2o21+JSBoePPPRdanz4dnnyyHBOnlFL+0KAQy/jxwbqCc+t9SpMm8BduiX3+ggXe+42BKVNg/34fEqmUUmVLg0IsNWtCly4AZB3ayU03wb8Zwjf08D4/VvHRjBkwfDjcdZdPCVVKqbKjQSGemjXt44EDXHstNGA7DzPG+1yvTmwLFsC4cXY9P9+fNCqlVBnSoBCPKyg0aADX8yRvcwFL6BB9rldOoUcPWwkNOjSGUqpS0KAQjxMUAp3TRvM4Wezlz9wefW6i4S40KCilKgENCvG0aAHXXQdTpwKQy2ZG8SwvM4IfaRV+bqImqRoUlFKVgAaFeDIy4KmnoGvX4K5b+AvVOcSdRIx59Mor9sa/dSu8+GJ0ENCgoJSqBDQolFAL1nE7f+ZVLmUWA6JPmDgRrrwyer8GBaVUJaBBoRTuYBxtWMV1PM0BaoQf3LjR+0mJgsLGjdCuHaxYUTaJVEqpUtCgUApZ7ONv3MBSOvJXbgo/eOiQ95NEbIX19OnwySfRx994A5YvhwkTyj7BSimVJA0KpXQW0ziX97ifsayhZejA7Nmxn3TLLTB4MJx+uv8JVEqpUtCgcBgeZzQAlzOZQ1SzOxcu9D5ZBGbODG1HNmHVOgelVAWgQeEwtGINz3AN/2EAd/NA/JNF7BSejp07vc/T0VaVUimkQeEwXcbLjOLvjGMMUzkr9oki4fUNhYWh9Vmz4LHH/EukUkolSYNCGXic0fTgGy5nMqtp7X3SpEnhOYXt20PrAweGpvdUSqkU8jUoiMhgEVkmIitE5I445/1aRIyI9PYzPWXqjTeCq5ns500upJgMBvNvNpHr/Rx3UOjWzQ6YN2eOzwlVSqnk+RYURKQa8BQwBOgEDBeRTh7n1QNuBOb5lRZfXHhhaL24mKNZxVTOZi0tGcQMtpEd/ZzIeoQ+fcIm8ym1FSvg7bcP/3WUUmnPz5xCH2CFMWaVMeYAMAU41+O8B4BHgH0exyqWSy7x3h9oOXQSX/Le9NosoSND+Iid1A0/z12PAMGB9sKUpqL5uOPg178u+fOUUiqCn0GhObDWtZ0f2BckIj2AlsaYqT6mo+y88krCUwYNgte5iDx6czozYxclxTJxop2YB2zR0q23Jn7OgQMlew+llIrBz6Dg1fA++DNYRDKAv0K8OS6D544SkTwRySsoKCjDJJZSq8AIqc88Y3soRziP93mLX/MtXejHHJbRrmSvf+ed9rF/f/jLX6JzD7Nne76vUkodLj+DQj64u/rSAljv2q4HdAY+E5Efgb7AB16VzcaYZ40xvY0xvXNzS/jLu6z9+GOog9pvf2uzBgBDhsC119r1CRM4j/eZxanspB79mc1nnJL8e0QGgchiphNPtD2jP/0Uvv02tD/enA5FRbBpU/JpUEqlJT+DwtfAsSLSRkRqAhcDHzgHjTGFxpgcY0xrY0xrYC5wjjEmz8c0Hb5WraBBg+j906bB00+H7TqBr5hLX3Ip4DQ+4V7uCfV8jidWUFi2DM51VcucdlrYsN6edRSOu++Gpk29A4Mx4S2jlFJpy7egYIw5BFwPTAeWAG8YY74TkftF5By/3reiactqvuZ4LuUV7uNeBvJp+FhJXr75Jnzbudlfcgl88EH0+Y5Yg/EBvPeeffQqfrv5ZqheXXtTK6X87adgjJlmjGlnjDnaGPNgYN9YY0zUnc0YM6DC5xJKqR67mMwVTOYyvqEnx/EdExidXK4BbFBYtCg6WHidVxrOyKyJphRVSlV52qO5HF3Gy3xLF07iC25iAicwj3n08T7Z/av/s89sR7dEInMKkybZOhAI5QJEbG/qZ56Jzhl4FSEZA//7X+L3VkpVCRoUylkbfmQaQ3mdYaznSPoyj4uYwkrahp94/PGh9WHDYPz4xC++z9XV4+BBGDkSTjrJbi9dah9F4KabbKX4f/4T/nyvoPDkk9Czpx2fybF3r30dnftBqSpHg0IKCDCMN1lGe+7mfqZyNh1Zwu94MlTfEJkzSGZsJPc0oM4Nfv368HOWLIEXXrDr8+aFz/R26BCMGGFzJg4nHatWhfZt2WIfkwlUSqlKRYOCH6olV1dQn53czz2s4BiuZhL/4P84mpVczT/5gWPDT65ZM/ELumd0c4KCMeE5iAsuCK3fcQcc63qfXbtsB70zz4z/Pk7dQ4Z+fZSqavS/2g8jR9riGfev9Pvvj3l6MzbwDNeykqO5lom8xnA6sJRf8gGfcqrt8Rdr/oVY3PUL552X3HOc96jhmnfaq0WSX0Hh++9t01ltBaVUymhQ8ENWlu2z4HS0q1cvema1Z5+F554L29WSfJ5gND/RirHczzxO4DQ+pRsLmXjoN9FjKcXjrh9ItvezMzZT9erRz3Wn33ntREFh/vzYTWgLC2HbtvB9p54Kf/pT+LDiSqlypUHBT9WrwxNPwNdfh/bdeaf9Jfx//weXXur5tCYUcC/3sYajeI6RVKOI65jIkaznGiYyjz4k/C1dms5oO3aE0g2QlxfK7UycCF99ZdedXEiiYrLevcM727llZ0OjRuH7nGKuZKYmNUZzFEr5QIOC3264Adq3D227b2TuYhoPmexnJJP4hp7MoS/n8w4vcgV9mUdnFvNn/hDdEW7tWpg7FzZsKHlanaDgpMvdAiovD044wa47A/A5OYWy6g3t/G3cf6Ply21gdUyYYOe67tMnOqeydWvZpEOpNKZBobx4/fp139Quuwzq1PF+KtCXebzIlWzgCP7Bb8hmO3fwZ1qxhpP4L09xHetpBkcdBf36hQ9/kazIoODl559h5Uq7Xq2aHdG1evWy6cvg1FW4g0z//jB6NOzfb7dvugnOOMMGKbeZM6FxYx0oEOzfUcQOpqhUCWlQKG/uX8FOoDjmGJg8GZo0CT+3a1d48024997grgbs4Df8ky85iZW05UH+yHayuZ6naEE+J/IFj3FTdL+HZDh1CvGCwpFHwq9+ZdeXLg1N7jN3bsnfL5Lzt3EHhc2b7WO8ITwAvvwy/DGdOT3b//jH1KZDVUoaFFJt7lzbXwBshbRbvXp28pyePT2f2pbV/JGHWUwXvqMT93EPu6nDLTzGMazkOBYzhof4kv4UJfNROzmF4mKYmuQUF04g2bs3dl8K52ZfUOA9lMZPP8F334XO8woAiYbwcAJsZD3D5s2lH/6jskoUQJWKQ4NCqp1wQqjC1ZnZ7cQT7aMTJJztoUNjvkwnlnA3f2IBPVhJWyYwmqZsZDy3cRJf0oRNXMrLTOYyNtDU+0WcJqk//gi//GVy6d+40T7ecgu0jZE7OXDAFv80aWIr2CO1bg2dO4fnFHJy4LHHQuckGxTciottC7CRIxNeRpXi/K2SqbBXKoIGhfIS65es2x/+YH/ZTpxot88+2z42amR7ET/+eFJv1ZbVjOYJPuU0NpPD6wzjbKbyMWdwBZNpxgZ68A23Mp6PGMwuAnUZTk6hJCIrtLduhSOOgKOPDu3btw/27LHrkybFfi13ncKWLTbQOJL9te/++zojwr7zTnLPTda6daF6lYooVlB46y07dWsyAx/Om6f1M2mqeuJTVLkRsZWljRtDfr4tv3c0alTyDmxANoUM402G8SbFCAvoznTOZAaD+Bs38BdupToH6cV8TvnPJk7hJ/ozm2wKE784RAeFxo2jz9mX5PTbzg3dKwAcPBh/qA+vX8U//xw7TY5//cvm0DZsiK7oP/98u++ll+w8FB07wscfQ69e4emtaGIF0CuusMF5zx6om6DPS9++9rGiXqPyjeYUykuHDvaxU6fkzm/ePPpGd5hlxRkYevI/xjCOWQxkGw2ZwRncxniqUcRflwzmLKbRiK10YwG/40le4RJW0SZ2v4hkOpq1aRM+j7QzBzWEVyo7NzN3E173sVjFU27um5hTSZ2dHfv8MWPs8B4rVoRyM45334WXX7br06fbXJC7SKuiihUUksmtqrSnQaG8nH++bUY5YkTpX6N2be/9U6fCjTeG73PqJ+K9HHs5g5k81O0NvuQktpPNJwzkXu6lKRuZzOWM4BWOZhXN+JlzeY+HGMMnDKSQ+smne+/e8FyOe7C/P/85udeIdaObPdve7NyjuDqcZqzVqtn+G15B1blBjhljcwWxcjVlObSHMf5Ojer8rfbts38bJ7A5Kusse8aEBmNUvtGgUJ569Tq8yr9mzWxxR6SzzoJf/CJ8X+TNy6uC19HUVjzXZi8DmcVYHmAGZ7KNhvyP7jzNtQxiBkvpwJ08xOl8QjaFdGAJl/MiT3ADs+nHHrJiv8e6daH1+fND63feGfs5bu6chptTCf/pp/bR/SvYec6uXbb/hjOH9v79MHasHWbj++/tvo8+so9eM9NB7KDw7rswblxoe+JE228jXrn944/bv/ny5bHPcYwda5srl0Rk8LvnHvvofPfKs3XSokUwZ07ZvNakSbYBgnte8sNx8KD9v/jpp7J5vSpCg0Jlc/bZofJet8i+Bc4QFI0bw5Qp8XMoOTmeu6tTRHcWci3PMJkrWEYHttCIf3MmD3AX7VnGx5zBaJ7gRGZTnx10YRFX8jx/43q+pH9ovCZ3UHjjjRJccIDTNyIRr6Dg5BheecU+/uMf8MAD3hX3TmuqSLGCwvnn21yG46ab7C9xd45j3z4b/JziqWnT7KN7OPJYHnjA1gXEsmFDeN+MoqLoABqZyyrPoNCtm+2AmKzi4ti5Nafi2wnkh+uzz+z4Y+nWOi0BrWiujBJl/2++OTTY3COPwEUXxS9H7tIl6bduxDbOZAZnEqoXWE8z8uhNHr2ZTy8+YggvcmXw+NGsoMtV33IcD3Ac39GJ72nHD2SRZAU0JDefBNjrzMuzlcNO/w7nprh3r3105pBw3+Czsuzx5cvteE+7doWOHToUCgqJbqg1atggtGdPqLjvySfhoYfs8t574bPgHa4LL4QvvrC9vJ3e5Z07h58TmWZn+803bdPjzMzYr19UlPRQ8GXiN7+B55/3/r46n1dZ1YkkU8f4kJLlAAAcHUlEQVSyfbvtBPjoo7GLb/22b5/9TjVoUC5vp0GhMoo1bSbAOefY4Q2cXz/OzSzWDejRR8Nb3Zx+uh0yogSO5GfO4V+cgy3aMsA6mrOQbiygOwvozmI68y9+SVHgKycU04qf6MBS2vED7fiBY1nOsSznKNZQjcOYL9o9ZhNE/1J2BvZzilUg9Df1qot59NFQZfVLL3m/5w8/QLt2ocEE3ZXW7qa+EyaEJjESscFn4kQbyJO5+e7aZW/izvs4dRMffxw6Z/Hi8OdENlEtKrKz7g0bZq935Eho2dIGli+/tI0cHHv3xm+ptH8/XH+9HRq+WbPQ/uLi5HJCkZ5/3j4aE/2ddYJCcbHtNFmjRuwb9f332xF3YxU7Rr5eLA89ZD+fdu3g979P7hrKWvfusGxZuTUQ0KBQGTk3sMcfj24e6XzRk/nCg/1V6R5e4557ShwUIgnQgnW0YB1nMS24fz81WUZ7ltIhuCyjPV9wErsI9eauyX7asJqjWRm2tGUVbVgdP4fhVXHtDgqTJ3uXcce7eYwZYyckivTmm6H19u3tZ+AU402eDAMG2OlQneIrCL/Ridj5IyZMsE2Oly+3N4CGDaFVq/AJkBz16tkbuVMU1qSJDUjxRAaFm28OFUm9+qpdbrjBlq1PmRJe/+QOCnXq2PS6/xZdu9r3LywMLxZ8+GG466746YrnwAGoVSt8n/s7nZ1t64li1Qc4AT8yuLi3k8kpOP8/qewVv2xZub6dBoXKyAkKAwaEBr6LzBE4vzoTBYVataBHD9sv4p//DC//7dGjZAPd1a4d3azT/VYcoCvf0pXwikID/EyzQD7BLis5mhUcw+ecHBYwAJqygTaspg2rac2PtOZHWvETrfiJo1hDbfaGv7H7hh+vfD4er7qGYcPCt91B4e67Q/tiBYUzzgit/+Y30a/frVv4tvNZvvpqKCi4ixRi3dwib2jvvANXXRWddoB//xtuvTW03/k8jbHrY8bA734X6m3vBKSNG20uxgkgn3/unZZk7d9v66EyMmyPdwgFhb/9zT6uWZP4dQ4eDM1a+PHHMGiQ/U5365ZcUEj2/6gK0aBQGTlBwV3cEFlOnWxOwSlqad7ctnQBOwHQggW2LLwkTTDr148bFGIRbBHUkfzMKYTfTAxQQC6raMtKjmY1bfiR1qymDfM4gTe5kEOEV7I3ZjNHsYaWrLXL/nW0YA0tyKc562jOupLVZ0CoWCOeAwei58QGO65T8IJKUASwcGFofeZM21PcsWiRvbG5GwnE+jXr1CG4A1Lk5+qkK/JHgFMP437t3bujx+n6/HPbourpp21RVKR33rE356FDbeAZMsSm57vvbPFav37h5+/fH+oVH/nddor/AN5/P/acHWC/j05QePdd+zh7tq1gfuqpUNpfeCF8jnNHWQwP//77dvbDwkL7P1LB+RoURGQw8DhQDXjOGDMu4vjNwG+AQ0ABcLUxRtuHJeJ8sdwtjpwvr/uXan5+4n4RXsN1ezVfffjh8FY2sdJVmnkc4pAxY2jy8MM0oYC+zIs6XkQG6zmSH2nNGo7iJ1qxhqNYS0tW0Zb/cAqFxdGd1xrKNo40NkAcyfrg0oyfg8sRbCCT/VHPjenRR733u4vjSjs8hjtXAaHP1emgB7ErwQ8etN8F9w8Ed2swCN14d+8O3//66/bHgjsoOK8zblz4uXv2hG6sgwaFH3PmBn/iCdunZsoU2wDCqRSPDJb7Pf7uXj9QEuUWvv3WFuGJhF6zZs1QQHBcdZUNsh072vU//ckGpcgfV08/bZtBd+tmA8X330c31GjY0BbrOp+7MxXv8uWh4t5E9u+3TbdL0nKrrBhjfFmwgWAl0BaoCSwEOkWccypQO7B+LfB6otft1auXSXtr1xrzyCPGFBeH9h04YMz11xuzYUPs54XmKwstiTjn7d5tTLNmxpx1lvfrgDF9+4bWf/EL+3jNNcY0bWrXH3009nNjLePHl/w5EctO6piltDMzGWhe5DLzEHeY61q8b87jHXM880xz1ppqHPR8ejZbTUe+MwOZaS7lJXML480j3GomM8LM4HSzkC5mA03MITK833/GjMNOf1JLbq4x27eX/vnXXBP72IcfGrN1a2j7p59if5+cZdAg7/033hhaf/nl6O+hs/3tt6H1jz825uabjbn66ujXmzAh/Ps6daoxJ5/s/T0fMcKuv/hi7HR/8ol9HDDAPufuu+32vfeGp88YY8aOtevDh3v/zzh69LDbN9xgTFaWMQcPJv6/c6519ero1yslIM+YxPduP3MKfYAVxphVACIyBTgXCDYyNsbMcp0/FziM7r5ppEULuO228H01aoTKWpPRoUPs+ZO91K5ti0aeew4+/NDumz8/9MvnP/8JL4t2frX+8pehYS3cZeSFhaHy8HhFAJFTdpZCXXbTnh9oj6tCdtDVYYPzFZHBZnJYz5Fs4AhXfiG0zKEfP9OMvUS3eBGKyWEzTdgUtuQO+pwmjCKXgrClIdvISDypavJ27Di8ytB4xSM7doTXyxw8mLhlUazWbu6Oi/Fysc53DEK5JK/+BMbYup2mTW2F/YUXhoq8Ijl/n3gD/TnfNyfHawKf0YoVttjJsXdvaMj7116z9TwQPu+4MbYnvfMazv/nrl22CfRVV9nK8nbtbK5pyxa7DaHvZrLjhpUhP4NCc2CtazsfOCHO+SOBj3xMj/r2W9tx64knbPM6r9YtiWS5ei337Gmb6zVvDiefHF584TThdM8A564UrVfPFkv07Gmb0cYKDCUNCi1b2n/EREaMCAsK1SimKZtoSvzhJwywg/pspGnYsokmwcdNNGE+vSggl0K8x13KoIjGbCGHzWGP7qURW4OPjdhKQ7bFrgvZv//wZlqLLDZy27QpPOCceWbiYrBYN954kyC5i4K8iiG90mhMqBXYk0/GnL2Qv/41VHzk3MC9OC2mNm60vdv/9Ce7/fLL4cOF1K5t60Uiub+vo0d7/1ArLoaLL7Z9VhyffmobD+zYEV5fE+9z8YmfQcHrp4LnTyMRGQH0Bk6JcXwUMArgKCeSqpLr3Nk2Y732Wu9B57x07x7egzqyEvGaa0Lrr70WGvjv+edt088WLULH3e3dReC++0Lbkc0PHQ0bhtYvusiWccfSsiWcemr4sBB//KNta+524onhwS2W+vWjhhMX7Ox3DdhBOxIPU7GfmmwmJyKfkBvc54SAlRzNV/RhMzkcIMbfAshiT1iQCFvGbaMhvyOb7TRkW/CxAYVks53a7PH8pwRCkyV5GT0aTjsttO3HsOFLl4aGLIHQGEfVqoVyMe6+GI7IhhSxcig332xnOEzEyaFs3564fsxdx3H77dF1LLFy7tdeGx4QIJTrWLjQ1oE43J9L3762LiTZeolS8jMo5EPYrPItgKimGSJyOnAncIoxxrNWzxjzLPAsQO/evcswz52mnBt3MiJbo5x8sr3hd+8efW779vamvXGjzc6fd57d37ixLW5wWoF4cXrVHnUUjBoV+sXm/uV38cXhQeG112D48NC2SPRNwf2ry6nkhOSCQqdOhz3NaC0O0Hzj/2jeNMbERhEMsJs6bKVRMGBso2FwO3J9FW3ZSiO2k81u4g+HXZ2D1GcHDSgMLtlst+vzs2jACWHH67MjtDwwmfpkU4+dVMeHAfU6dgzfdm7I7mItr8HwIgdCjFeE5vRkT4Yx0ZXRkdxFXI88EqpMT8RrmBfn+5+XF96p0v2jZN688J72PvEzKHwNHCsibYB1wMVAWHdREekB/B0YbIzxcdhIVaa8mu45Itvug53HecqU+ENfOzmF4mL7q84JCu4hGCJv5BdfHB4UMjKihwJwBxWnSEskuaBQvYz+PXJzYx9zhtcIEGwdSF12cxRJFIO5HKAG28lmGw0ppEHU+nayXeHALqtpY9c3ZrODCygmRq/q1wFsx8As9lCfHdRjZ/Ax1lKXXcHHyHVn8QwyXrkCL+4bM3i3Wiqtv/+9ZOefEK90PAEn+N10U/j+yImv4s2fXkZ8CwrGmEMicj0wHdsSaZIx5jsRuR9bC/4BMB6oC7wp9hfeGmPMOX6lSaVIy5ahivHly8Mr4xxOUCgqCr9hZ2babPPcud5j9DRqZOc5AHuzf/BB257/5pvtPnfFprvosTRB4brrbJNELzk5NvitXAlXXx1+zKtI4+ij7blHHJH8uE4J1OQgTSigCTFGeo3H2FzKLuoG8weFLTqzI7/QrtMgeKt3r++gPjupxzqah4WDPcQo2/dQi33BAFGH3VHrddhNnWr7qVu0nTrspjZ77D6PxX2sNnsOb7iU8hRrXpKqFBQAjDHTwDXOgd031rV+up/vryqgWOW67pwChG72tWqFbs7uMlyv+RMyMmy9hbs/Rf/+th7FmPDnJ5p5DGxHK2ecIrDl6rGCQqNGtmjt5JPtiK4vvBD9q8/tV7+y/RrcQeGaa+CZZxKnyycC1GMX9dhFc9bDnk3A1lK9VhEZ7KZOMEg4+YKd1Avb79zOnXXnPKcIzVnfbeqxi9qxczIx1GIftdkTd8lir+d2FnuDi9d+93ot9seur0lGrHkiIoNCvCLYMqI9mlXF4M4pgK1XGDcu9s17wIDofbEqGZ16BGfoBWNsBfaZZ4a3krn9djt2UqdOtviicWM7b7bDXQz09de2Jdezz9ptd8DJzraVs+3bh3rqdukSPg+A0/LLPfnQCSfYoHD++Tbn4bz2++/b1i5O08zLLrN1K/HGayoLXjm6RLp2hUWLqEYx9dlJfUo+haynwUMx06axn1qeeYQ91A5bdxb39m7qsJes4L6tNArbv5esEuVwImV6BJNM9nmuu7cz2UfWAfvo3pfJPrK+zSGTvsF9ubsziTO5bJnQoKAqhsicwoMP2n4PDRuGio28bvoDBtghFCDxkBzO6J8DB9rH/v1tUMjMtO3Bnd61InZ+7MiWLU59RadO0Lu3bU573XW20j2y3kDEu8mi49RT7aN7WAynZdfVV9schxMUzgmUqHboYFvpvPiibWFVFkNvx2NitOlo2DB2wIg3DLcXd1+XeHJyECCT/WSyn8aROZi77go1Hz0MBthHZjB47A27jWcFA4xzjnt/5Ll7yQqet42GUfuc9bi5nykQaHgJwB9e2Mqf/e7knEwPt4q0aI/mKmrTJttrs0GD6GNr1xpz223GHDoU3btzzx7b4xWMGTky8fusWmVfxxhj7rvPPu/uu43ZudOYhQvtdufOofPdvV337DGmcWNj3nsvdLy42Paq/fnn+O/btWt4T97iYmNGjTJm5kxjnnvOmOeft+dt3Ggf9+6NvtZNm4z54gvvtE2aFL59yinh2w8/bMwf/hC7J29JljPOMOakk7yPefUmjrfs22fMtdeGtt96K7R+zz32sV8/Y556Kv7rFBYa06VL2Vzf4Sxt25bo/GIwB6huCqlnNpJrfqKlWUo7s5AuZi59zCxOMf9mkHmXc81rXGS+mbou8Xc8BpLs0VyiG3JFWDQoVFHOEA316sU/L/JG6Vi0yN5gSsIJCnfdZbedwPTQQ9Hv16RJyV47UrdusdPuxSsARnKOv/uu3S4stAF0wwZjBg4MvwE511RQYLevvDI0hMMVV9hhU5o3T+5mNniwMSee6H0scniLWMHDfW3uQPDll6H1rVvtMA/FxdFBL3IpKjJm3rwS3ZB9WS68MPlzYw0FEm/Jzy/tNzDpoKDTcaqKwSk+StSs76uvoieiB1tmH6sDXCxOsYzTnyI317YD95o7oSRt3L04RUHJKslsZ07669e3nQWbNo1ur2+MfczJsevPP28HajPGVorfdpt33xMvkcV07kl5IouPvIacePxxOO640LAV2a5e3+5RRBs2tMNmiyQulsrIiDmtrKd//jP5cyO1ahVad//NBg4MH8k2ngULoE8f72POAHpeyqH1kQYFVTFkZtrK27ffjn/e8cfDpZeWzXt2725viu4y7Tp1vMvqI4eKLqlYN4DDsWpVeJNbN6e9vhNkk5kP4NVXbasuZ+4IEe/eyxkZoZ7q33xjR2B1RHZC86oMv/FGOzvcc8/ZbXfv+lh/Z3dQePppu/3xx+H9UCKDwn//axsDuN19t+1N3LgE1bVOB0anTunii+17f/dd+Ex9U6aEgq+jbVv7d/3b38L7PXTrFrujXbwfBJW9SapSJdK7d6pTEO3NN0s0h3WZ+stfbIVzLG3a2MWLExSc1lvJBIX69W3FvdMiyhh7U/v0U9tstn9/e9MfOtQG5rPPthMxud19t/0lfd11dvv1123FPNjh172G0/DKafziF+HnuIPCtdfaBWwOzqn0rl/fDvL429/Czz/bvihOc+aLLrI9lJ1g4O5VvHBhaLDGJk1CU5w6TjjB/i0efNBWaGdk2GlrIdTzevp0m9OMzEV17BjqYFlUZAPM+efb7VhDnXvNdeH8UCmHoJCwfKmiLVqnoCotMKZVq/J5rw4d7Pudd559vOee5J974ECoDDtSQUH4kO2O+vVDZfvGhD/fWfd6nqNRI3vO5s3GrFhhK/7dPv00dpoiOUO4f/GFMS+9ZNcvvjj8HHcdxbZtofUjj4wux3fMmWO3Z80Kf63Nm0Pr7tdy/v6xuIcRdy8bNhjTs6f337Ck9WYuaJ2CUhXM1q3hs7D5ySm2cYpXIos14ok3vEdOjnfx2ldf2T4WXs2Cv/rKluHHa0LrTJNau7bt7R3ZP8XJKbhzFbE89pjtB9K1a+yiGGf00euuC6/TcNI/ZUr0c/r2tb/uI/vIuIuisrPDi0DjDeDpFB+503jppbZOaP58GD8+epwkLT5Sqgpxj/jqN6f4yOlBfuSRyT9XxN783R33EmnfPvbIu8cfH5r2NZbx4+2oubGGH3GCnLuSN5Z+/UJzR9cOzH0RWWzl3JAjx8pygoJ7ZGC3ZBoAnH++nRFv6lTvscAi0/DUU6HRhl94IXTcPT9JZPp8pEFBqaqoc2c75eaNN9ry8njzGHspKMX4SYejWrX4lfnNmtnHyy8v2eu2bm0fI+fYGDXKVtQ7Q6IMHmznjo6cfrO0N+HGjUO5n0TcQ1fEyqVNn257tpcDMSXJVlYAvXv3Nnl5ealOhlIVW2GhHfbcaziQ8uAUFZXl/WXLlpK1GgJb3HPZZXaAxES5FYCzzoJp02xAzcuzleTJzMNQGps2wZ132pZJTg7Jx/uxiMw3xiRszaFBQSlV9nr3tvMLuAcnrAwKC+20m/GGKPGDH0E06i2SCwpafKSUKnuV9YdbgwblHxAqGA0KSimVaq+8YvtIVAAaFJRSKtUuuSTxOeVE+ykopZQK0qCglFIqSIOCUkqpIA0KSimlgjQoKKWUCtKgoJRSKkiDglJKqSANCkoppYIq3dhHIlIA/FTKp+cAm8swORVNVb4+vbbKqypfX2W6tlbGmNxEJ1W6oHA4RCQvmQGhKquqfH16bZVXVb6+qnhtWnyklFIqSIOCUkqpoHQLCs+mOgE+q8rXp9dWeVXl66ty15ZWdQpKKaXiS7ecglJKqTjSJiiIyGARWSYiK0TkjlSnp6REpKWIzBKRJSLynYiMDuxvJCIfi8jywGPDwH4RkScC17tIRHqm9goSE5FqIvI/EZka2G4jIvMC1/a6iNQM7K8V2F4RON46lelOhohki8hbIrI08Bn2qyqfnYjcFPhOLhaR10QkszJ/diIySUQ2ichi174Sf1YickXg/OUickUqrqU00iIoiEg14ClgCNAJGC4inVKbqhI7BNxijOkI9AV+F7iGO4BPjDHHAp8EtsFe67GBZRQwsfyTXGKjgSWu7T8Dfw1c2zZgZGD/SGCbMeYY4K+B8yq6x4F/G2M6AN2w11npPzsRaQ7cCPQ2xnQGqgEXU7k/uxeAwRH7SvRZiUgj4B7gBKAPcI8TSCo8Y0yVX4B+wHTX9hhgTKrTdZjX9D5wBrAMaBbY1wxYFlj/OzDcdX7wvIq4AC2w/2wDgamAYDsFVY/8DIHpQL/AevXAeZLqa4hzbfWB1ZFprAqfHdAcWAs0CnwWU4EzK/tnB7QGFpf2swKGA3937Q87ryIvaZFTIPTFdeQH9lVKgSx3D2Ae0NQY8zNA4NGZ6LWyXfME4A9AcWC7MbDdGHMosO1Of/DaAscLA+dXVG2BAuD5QPHYcyJShyrw2Rlj1gGPAmuAn7GfxXyqzmfnKOlnVWk+w0jpEhTEY1+lbHYlInWBt4HfG2N2xDvVY1+FvGYRORvYZIyZ797tcapJ4lhFVB3oCUw0xvQAdhMqfvBSaa4vUCRyLtAGOBKogy1SiVRZP7tEYl1Ppb3OdAkK+UBL13YLYH2K0lJqIlIDGxBeMca8E9i9UUSaBY43AzYF9lemaz4ROEdEfgSmYIuQJgDZIlI9cI47/cFrCxxvAGwtzwSXUD6Qb4yZF9h+CxskqsJndzqw2hhTYIw5CLwD9KfqfHaOkn5WlekzDJMuQeFr4NhAi4ia2IqwD1KcphIREQH+CSwxxjzmOvQB4LRsuAJb1+DsvzzQOqIvUOhkfysaY8wYY0wLY0xr7GfzqTHmUmAW8OvAaZHX5lzzrwPnV9hfYcaYDcBaEWkf2HUa8D1V4LPDFhv1FZHage+oc21V4rNzKelnNR0YJCINA7mpQYF9FV+qKzXKawGGAj8AK4E7U52eUqT/JGz2cxGwILAMxZbHfgIsDzw2Cpwv2BZXK4Fvsa1DUn4dSVznAGBqYL0t8BWwAngTqBXYnxnYXhE43jbV6U7iuroDeYHP7z2gYVX57ID7gKXAYuAloFZl/uyA17D1Iwexv/hHluazAq4OXOcK4KpUX1eyi/ZoVkopFZQuxUdKKaWSoEFBKaVUkAYFpZRSQRoUlFJKBWlQUEopFaRBQaU9ESkSkQUislBEvhGR/gnOzxaR65J43c9EpErN36uqPg0KSsFeY0x3Y0w37GCJDyc4PxtIGBSUqow0KCgVrj52qGdEpK6IfBLIPXwrIucGzhkHHB3IXYwPnPuHwDkLRWSc6/UuFJGvROQHEflF4NxqIjJeRL4OjMH/28D+ZiLyeeB1FzvnK1Weqic+RakqL0tEFmB72zbDjr0EsA/4lTFmh4jkAHNF5APsYHadjTHdAURkCHAecIIxZk9gLH1HdWNMHxEZih1f/3RsD9lCY8zxIlIL+FJEZgDnY4eYfjAwB0ht369cqQgaFJQKFB8BiEg/YLKIdMYOYfCQiJyMHdK7OdDU4/mnA88bY/YAGGPcA7w5AxfOx47RD3YcnK4i4owN1AA7ScvXwKTAwIfvGWMWlNH1KZU0DQpKuRhj5gRyBbnYsaVygV7GmIOBUVwzPZ4mxB4WeX/gsYjQ/5sANxhjogZICwSgs4CXRGS8MWZyqS9GqVLQOgWlXESkA3ZKyS3YX/CbAgHhVKBV4LSdQD3X02YAV4tI7cBruIuPvEwHrg3kCBCRdiJSR0RaBd7vH9gRcSv03MyqatKcglKhOgWwv+KvMMYUicgrwL9EJA87Ku1SAGPMFhH5UuzE7h8ZY24Tke5AnogcAKYBf4zzfs9hi5K+CQw3XYCtkxgA3CYiB4FdwOVlfaFKJaKjpCqllArS4iOllFJBGhSUUkoFaVBQSikVpEFBKaVUkAYFpZRSQRoUlFJKBWlQUEopFaRBQSmlVND/AyRF1aB0T7GKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fda00618eb8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratio = len(stats['train_loss']) / len(stats['test_loss']) \n",
    "plt.plot(np.arange(len(stats['train_loss'])), stats['train_loss'], color='red', label='train')\n",
    "plt.plot(np.arange(1, len(stats['test_loss'])+1)*ratio, stats['test_loss'], color='blue', label='test')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "\n",
    "In this section we implement the same NN in tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tfk = tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfmodel = tfk.Sequential()\n",
    "tfmodel.add(tfk.Input(shape=(2)))\n",
    "for i in range(nLayers):\n",
    "    tfmodel.add(tfk.layers.Dense(nHidden, activation=act))\n",
    "tfmodel.add(tfk.layers.Dense(nClasses))\n",
    "loss_fn = tfk.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "tfmodel.compile(optimizer=tfk.optimizers.SGD(learning_rate=lr), \n",
    "                loss=loss_fn,\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have a look at the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                192       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tfmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.9619 - accuracy: 0.5455 - val_loss: 0.8710 - val_accuracy: 0.5393\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8485 - accuracy: 0.5455 - val_loss: 0.7710 - val_accuracy: 0.5393\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7514 - accuracy: 0.5455 - val_loss: 0.6870 - val_accuracy: 0.5393\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.5511 - val_loss: 0.6179 - val_accuracy: 0.6180\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.5966 - val_loss: 0.5619 - val_accuracy: 0.6517\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.6847 - val_loss: 0.5172 - val_accuracy: 0.7079\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7557 - val_loss: 0.4815 - val_accuracy: 0.8427\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.8722 - val_loss: 0.4523 - val_accuracy: 0.9101\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.9034 - val_loss: 0.4278 - val_accuracy: 0.9326\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.9176 - val_loss: 0.4067 - val_accuracy: 0.9438\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.9290 - val_loss: 0.3885 - val_accuracy: 0.9663\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.9375 - val_loss: 0.3726 - val_accuracy: 0.9663\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.9403 - val_loss: 0.3584 - val_accuracy: 0.9663\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.9460 - val_loss: 0.3458 - val_accuracy: 0.9663\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.9489 - val_loss: 0.3347 - val_accuracy: 0.9663\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.9489 - val_loss: 0.3248 - val_accuracy: 0.9663\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.9489 - val_loss: 0.3159 - val_accuracy: 0.9663\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.9489 - val_loss: 0.3077 - val_accuracy: 0.9775\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.9545 - val_loss: 0.3002 - val_accuracy: 0.9888\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.9574 - val_loss: 0.2934 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.9602 - val_loss: 0.2871 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2926 - accuracy: 0.9631 - val_loss: 0.2813 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.9659 - val_loss: 0.2758 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.9688 - val_loss: 0.2707 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.9688 - val_loss: 0.2660 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.9716 - val_loss: 0.2615 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.9744 - val_loss: 0.2573 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2633 - accuracy: 0.9744 - val_loss: 0.2534 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2594 - accuracy: 0.9744 - val_loss: 0.2496 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.9744 - val_loss: 0.2461 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.9744 - val_loss: 0.2426 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.9744 - val_loss: 0.2394 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.9773 - val_loss: 0.2362 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2420 - accuracy: 0.9801 - val_loss: 0.2333 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2389 - accuracy: 0.9830 - val_loss: 0.2304 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2360 - accuracy: 0.9830 - val_loss: 0.2278 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2331 - accuracy: 0.9858 - val_loss: 0.2252 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2305 - accuracy: 0.9858 - val_loss: 0.2227 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2278 - accuracy: 0.9858 - val_loss: 0.2203 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2254 - accuracy: 0.9886 - val_loss: 0.2181 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9886 - val_loss: 0.2160 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2210 - accuracy: 0.9915 - val_loss: 0.2141 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9915 - val_loss: 0.2121 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9915 - val_loss: 0.2103 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2151 - accuracy: 0.9915 - val_loss: 0.2085 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9915 - val_loss: 0.2068 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.9915 - val_loss: 0.2051 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9943 - val_loss: 0.2035 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9943 - val_loss: 0.2019 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2063 - accuracy: 0.9943 - val_loss: 0.2003 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9972 - val_loss: 0.1988 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2031 - accuracy: 0.9972 - val_loss: 0.1974 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2017 - accuracy: 0.9972 - val_loss: 0.1959 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2003 - accuracy: 0.9972 - val_loss: 0.1945 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1988 - accuracy: 0.9972 - val_loss: 0.1932 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1974 - accuracy: 0.9972 - val_loss: 0.1919 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9972 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1947 - accuracy: 0.9972 - val_loss: 0.1893 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9972 - val_loss: 0.1881 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1922 - accuracy: 0.9972 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1910 - accuracy: 0.9972 - val_loss: 0.1858 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1897 - accuracy: 0.9972 - val_loss: 0.1846 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1886 - accuracy: 0.9972 - val_loss: 0.1835 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.9972 - val_loss: 0.1824 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1863 - accuracy: 0.9972 - val_loss: 0.1813 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1851 - accuracy: 0.9972 - val_loss: 0.1803 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1841 - accuracy: 0.9972 - val_loss: 0.1793 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9972 - val_loss: 0.1783 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9972 - val_loss: 0.1773 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1809 - accuracy: 0.9972 - val_loss: 0.1764 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1798 - accuracy: 0.9972 - val_loss: 0.1754 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.9972 - val_loss: 0.1745 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1780 - accuracy: 0.9972 - val_loss: 0.1736 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1771 - accuracy: 0.9972 - val_loss: 0.1728 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1761 - accuracy: 0.9972 - val_loss: 0.1719 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.9972 - val_loss: 0.1711 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9972 - val_loss: 0.1702 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9972 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1726 - accuracy: 0.9972 - val_loss: 0.1686 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1718 - accuracy: 0.9972 - val_loss: 0.1678 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9972 - val_loss: 0.1671 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.9972 - val_loss: 0.1663 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1694 - accuracy: 0.9972 - val_loss: 0.1655 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1686 - accuracy: 0.9972 - val_loss: 0.1648 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9972 - val_loss: 0.1641 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9972 - val_loss: 0.1633 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1664 - accuracy: 0.9972 - val_loss: 0.1627 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1657 - accuracy: 0.9972 - val_loss: 0.1620 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1651 - accuracy: 0.9972 - val_loss: 0.1614 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1644 - accuracy: 0.9972 - val_loss: 0.1608 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9972 - val_loss: 0.1602 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1632 - accuracy: 0.9972 - val_loss: 0.1595 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1626 - accuracy: 0.9972 - val_loss: 0.1590 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1620 - accuracy: 0.9972 - val_loss: 0.1584 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1615 - accuracy: 0.9972 - val_loss: 0.1578 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1608 - accuracy: 0.9972 - val_loss: 0.1572 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1603 - accuracy: 0.9972 - val_loss: 0.1567 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1597 - accuracy: 0.9972 - val_loss: 0.1561 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9972 - val_loss: 0.1556 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9972 - val_loss: 0.1550 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = tfmodel.fit(x, y.argmax(-1), epochs=100,\n",
    "            batch_size=bSize, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have a look at the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XucVXW9//HXBxiYgRluM8ht0Bl/kWVeUAE17Ry1LFDTyo5562IXqpOllp600tRzTveT/jya/TA55tE0IksqUpQwSw0ERVPAQC4yA4wDAjPcmeHz++O7ZrOZ655hr9kza7+fj8c89l5r1uz5LLfs93y/37W+X3N3REREAPrkugAREek5FAoiIpKiUBARkRSFgoiIpCgUREQkRaEgIiIpCgUREUlRKIiISIpCQUREUvrluoDOKisr84qKilyXISLSqyxevHiTu4/o6LheFwoVFRUsWrQo12WIiPQqZrY2k+PUfSQiIikKBRERSVEoiIhIikJBRERSFAoiIpISWyiY2Qwze9PMXmnj+2Zmd5jZSjN72cxOjKsWERHJTJwthfuAKe18fyowPvqaBtwdYy0iIpKB2O5TcPenzayinUMuAO73sB7o38xsqJmNdvcNcdWUD9zh/vvh9ddzXYmIZNsHPwiTJsX7O3J589pYYF3adlW0r0UomNk0QmuCww8/vFuK660eegg+9anw3CynpeQprXku8Rkz4C0mTSqN9XfkMhRa+8hq9V+Uu08HpgNMnDhR/+rasHkzXH01nHwyPPMM9O2b64oSZs8e2Lmz5f7GRpg7F+65B556qtvLkjxSejfwhVh/RS5DoQoYl7ZdDqzPUS2J8LWvwZYt4bNJgZAl7rBgAUyfDr/8Zeuh0OTII+G734UzzoA+urBPYtAN877lMhRmA1ea2cPAycA2jSd03ZNPws9/Dt/4Bhx7bK6r6SFefjkk5JNPwv79XXuNnTuhqgoGDYJLL4Vjjmn9uGOOgTPPVBhIrxdbKJjZQ8AZQJmZVQHfBgoA3P2nwBzgHGAlsBO4Iq5akm7nTvj852H8eLjxxlxXkwPbtsGDD4a/6JssXw4LF0L//vD+90Nxcddeu0+f8Jf/xRdDSUlWyhXpyeK8+uiSDr7vwJfi+v355OabYdUqmD8fCgtzXU2WNTbCvHmtX07lDs8/H7p1du2CMWNCCACUlsJtt8HHPx6ei0hGet3U2XKwF1+EH/8YPvvZ8Adtr1ZdDW++GZ43NMAf/wj33gtvvNH2zxQXhw/+adPgpJO6p06RBFMo9GINDSEMysrgBz/IdTVdtHcvPPpoGMh98smW3z/7bPjRj+A972n9GtshQxLYPBLJHYVCL3b77fDCCzBzJgwblutqOukf/4Cf/Qzuuw9qa+Hww+GWW+D44w8cc9xxUFmZsxJF8pFCoZdatQpuugnOPx8++tFcV5Oh3bvhkUcOXM/ft284gc99LgwG6zpakZxTKPRC7vCFL0C/fnDXXd1w53JDA8yZA88+G355V2zdCrNmwVtvhev5v/OdcOv16NFZLVVEDo1CoRd64AF44gm4804oL4/xF61ZEwZ6Z8yA9euhoKDrf8336wfnnBNaBWedpev5RXoohUIvU1sL11wDp54KX/xill50794wRwaElsBzz4WB3yeeCPumToWf/ATOPTd8uItIYulfeDdwb392hM64+mqoqwvd8of8x/bSpeGF7r8/dOukKy8Pgxaf/nQYBBaRvKBQ6Aaf+lT43M2Wm26Cd72riz+8cyf86lchDJ55JnQJffjDB8/Xc8QR4VJQDfyK5B2FQsx27AiXjL7vfeECm0M1fHi4V6vTXnopBMEDD4RpId7+dvjhD+GTn4QRIw69MBFJBIVCzB57LFyJ+c1v5uCO4+3bwxQQ06eHeYAGDIALLwx3//7TP2nBBRFpQaEQs9/8Jky9c/rp3fhLFy8OrYIHHwzBcPTR4U63j388NDVERNqgUIjR3r3wu9+Fm8tiv2inrg5+8YvQKnjxRSgqgosuCq2CU09Vq0BEMqJQiNGf/hQ+qz/ykZh/0SOPwBVXhF923HHhBobLLoOhQ2P+xSKSNAqFGP3mN2ESz/e+N6Zf0NgYFlD47ndh8mS4447wqFaBiHSRQiEmjY3w29+G+706NYlnY2MYnZ43r+PVwpYsgT//Odwl/N//HQaSRUQOgUIhJs8+G5YGyLjraPPm8MF+771h+cfCwo4/5AsLwxjC5z53yPWKiIBCITaPPBI+06dOzeDgF14IN5CtWxduZrj9dvjgBw+sIiYi0k0UCjHYuDEsEzB1agbL+t5/f1hgecSIsMbwpEndUaKISKs0VWUMvvKVsGTw97/fxgENDeFa1fPOC3cUn3oqLFqkQBCRnFMoZNns2WFqoRtvDDNJtPDww1BRERaXWbwY/v3fYe5cOOyw7i5VRKQFdR9lUV0d/Ou/wjHHwHXXtXLAn/4U7io+4YQwqHzeeWFCOhGRHkKhkEXf/GZYi+bXv25ljPgf/wjzDh11VFigfvDgnNQoItIedR9lyfbtYR36K66Ak09u9s233gqtgn79wliCAkFEeii1FLKkaTbUFtNau8MnPgFr14buo8rKnNQnIpIJhUKWtDkb6i9/CX/4A9x2G5x2Wk5qExHJlLqPsmDvXvj97+GCC5rNhvrWW3DVVTBxInz5yzmrT0QkU2opZEGbs6F+/eth+orHH9fSliLSK6ilkAWPPNLKbKhPPx1Gnr/6VZgwIWe1iYh0hkLhELU6G+r+/XDlleEmtW9/O5fliYh0irqPDtGzz0JtbbOuo1mz4O9/DyuhDRqUs9pERDpLLYVD1GI21MZGuPnmsC7yRRflsjQRkU5TS+EQPfoovO99abOhzpwJy5aFS1E1uCwivUysLQUzm2Jmr5nZSjO7vpXvH2Fm88zsZTN7yszK46wn2/bsgdWrwwqYQGgl3HprmPzoox/NaW0iIl0RWyiYWV/gLmAqcDRwiZkd3eywHwH3u/txwK3Ad+OqJw4bNoTHsWOjHQ8/DMuXh8HlPuqZE5HeJ85PrsnASndf5e57gYeBC5odczQwL3o+v5Xv92jV1eExFQo//CEce2wn1uAUEelZ4gyFscC6tO2qaF+6l4ALo+cfBkrMrDTGmrLqoFDYvBleegkuvVStBBHpteL89LJW9nmz7WuBfzazF4F/BqqBhhYvZDbNzBaZ2aLa2trsV9pFB4XCs8+GjXe/O2f1iIgcqjhDoQoYl7ZdDqxPP8Dd17v7R9z9BOCb0b5tzV/I3ae7+0R3nzhixIgYS+6cqiooKoJhw4BnngkL5mhJTRHpxeIMheeB8WZWaWb9gYuB2ekHmFmZmTXVcAMwI8Z6sq66OrQSzAgthRNPDCkhItJLxRYK7t4AXAk8DiwDZrr7q2Z2q5mdHx12BvCamf0DGAn8Z1z1xKEpFNi7F55/Xl1HItLrxXrzmrvPAeY023dT2vNZwKw4a4hTdTWceirwwgthhR2tlyAivZwuk+ki97SWggaZRSQhFApdtGlT6DUaO5YwyFxZCaNH57osEZFDolDooqbLUcvHeggFdR2JSAIoFLoodY+CrYeaGoWCiCSCQqGLUqGw7m/hicYTRCQBFApdVF0d7k8Y9eo8GDwY3vWuXJckInLIFApdVFUFI0dCwYK/hutStXaCiCSAQqGLqquhvBxYsSKsnyAikgAKhS6qroaxoxvDTWvDh+e6HBGRrFAodFF1NYwt2xM2hgzJbTEiIlmiUOiCXbtgyxYYO3Rn2DF0aG4LEhHJEoVCF6QuRy2pC08UCiKSEAqFLqiqCo/lg7aEJwoFEUkIhUIXpFoK/aNV4DSmICIJoVDoglQo9N0YnqilICIJoVDogupqKCmBkt1RS0GhICIJoVDogtQ6Ctu2hTuZBw3KdUkiIlmhUOiCqqrobuatW8N4glmuSxIRyQqFQhekWgpbt6rrSEQSRaHQSfv3w4YNMGYMCgURSRyFQidt3w6NjVBaShhTUCiISIIoFDqpvj48lpRwYExBRCQhFAqdVBfNbDF4MOo+EpHEUSh0kkJBRJJModBJqe6jgQ1hgEGhICIJolDopFRLoc+O8ERjCiKSIAqFTkq1FPZvC0/UUhCRBFEodFKqpdCoabNFJHkUCp3UFAolDQoFEUkehUIn1ddD//4wYGcUChpTEJEE6TAUzOxKMxvWHcX0BnV1aZejgloKIpIombQURgHPm9lMM5tilt9TgtbXp93NDAoFEUmUDkPB3b8FjAfuBT4FrDCz75jZ/4m5th4p1VLYti1MmT14cK5LEhHJmozGFNzdgY3RVwMwDJhlZj+IsbYe6aDuo5IS6KNhGRFJjkzGFL5iZouBHwDPAMe6+xeBk4ALO/jZKWb2mpmtNLPrW/n+4WY238xeNLOXzeycLp5Htzmo+0hdRyKSMP0yOKYM+Ii7r03f6e77zey8tn7IzPoCdwFnA1WEcYnZ7r407bBvATPd/W4zOxqYA1R08hy6VV0djB+PQkFEEimTvo85wFtNG2ZWYmYnA7j7snZ+bjKw0t1Xufte4GHggmbHONDUKT8EWJ9p4bmSails26bLUUUkcTIJhbuB7WnbO6J9HRkLrEvbror2pbsZuNzMqgjh8+UMXjenDhpTUEtBRBImk1CwaKAZCN1GZNbt1Nqlq95s+xLgPncvB84B/tfMWtRkZtPMbJGZLaqtrc3gV8ejoQF27lQoiEhyZRIKq6LB5oLo6ypgVQY/VwWMS9sup2X30GeAmQDu/hxQSBjDOIi7T3f3ie4+ccSIERn86nhsj9pLGmgWkaTKJBS+ALwbqCZ80J8MTMvg554HxptZpZn1By4GZjc75g3gvQBm9k5CKOSuKdCB1GR4xfvDhsYURCRhOuwGcvc3CR/oneLuDWZ2JfA40BeY4e6vmtmtwCJ3nw18DbjHzK4hdC19Kr2rqqdJTYZXsBv271dLQUQSp8NQMLNCQjfPuwh/yQPg7p/u6GfdfQ5hADl9301pz5cCp3Wi3pxqWkthcJ+oH0mhICIJk0n30f8S5j/6APBnwthAfZxF9VSp7iOiJwoFEUmYTELhbe5+I7DD3X8OnAscG29ZPVOLVdc0piAiCZNJKOyLHrea2TGEm8wqYquoB9OqayKSdJncbzA9Wk/hW4Srh4qBG2OtqodKDTTv3RyeKBREJGHaDYXoRrI6d98CPA0c2S1V9VCp7qM9m8IThYKIJEy73UfR3ctXdlMtPV5dHRQVQcF2LcUpIsmUyZjCE2Z2rZmNM7PhTV+xV9YDHTRt9sCBUFCQ65JERLIqkzGFpvsRvpS2z8nDriRNhiciSZfJHc2V3VFIb1BXp3mPRCTZMrmj+ROt7Xf3+7NfTs9WX5+2PrPGE0QkgTLpPpqU9ryQMIHdC0DehUJdHYwbB2zYCjmcrVVEJC6ZdB8dtPCNmQ0hTH2Rd1IDzcu2RmtyiogkSyZXHzW3E8jLT0QNNItI0mUypvA7DqyY1gc4mmhhnHxTVwclxa4xBRFJrEzGFH6U9rwBWOvuVTHV02Pt3Qt79sDgAXtg3z4oLc11SSIiWZdJKLwBbHD33QBmVmRmFe6+JtbKepjUWgr7t4YnY8fmrhgRkZhkMqbwK2B/2nZjtC+vpOY92vdWeDJ6dO6KERGJSSah0M/d9zZtRM/7x1dSz5SaNntvtIT0mDG5K0ZEJCaZhEKtmZ3ftGFmFwCb4iupZ0pNm72jJjxRS0FEEiiTMYUvAA+a2Z3RdhXQ6l3OSZYaU6ivDjcrlJTktiARkRhkcvPa68ApZlYMmLvn9/rM295Q15GIJFaH3Udm9h0zG+ru29293syGmdl/dEdxPUlqoHnzWoWCiCRWJmMKU919a9NGtArbOfGV1DOlWgq1rysURCSxMgmFvmY2oGnDzIqAAe0cn0hNoVC8caUGmUUksTIZaH4AmGdm/xNtXwH8PL6Seqb6ehg0yOm7Y6daCiKSWJkMNP/AzF4G3gcY8BhwRNyF9TR1dTB4YAPsQKEgIomV6SypGwl3NV9IWE9hWWwV9VD19VAyILqHT6EgIgnVZkvBzN4OXAxcAmwGfkm4JPXMbqqtR6mrg8EFu8KGQkFEEqq97qPlwF+AD7r7SgAzu6ZbquqB6uqgxLaHDQ00i0hCtdd9dCGh22i+md1jZu8ljCnkpfp6GOx1YXGdgQNzXY6ISCzaDAV3/427fwx4B/AUcA0w0szuNrP3d1N9PUZdHQxu3KJWgogkWocDze6+w90fdPfzgHJgCXB97JX1MPX1ULJnk8YTRCTROrVGs7u/5e7/z93Piqugnsg9ainsqlEoiEiiZXLzWt7bE63AWdK4QaEgIonWqZZCZ5nZFDN7zcxWmlmLLiczu83MlkRf/zCzra29Tq5t2xYeB+/folAQkUSLraVgZn2Bu4CzCWswPG9ms919adMx7n5N2vFfBk6Iq55D8cYb4XEc62DMGTmtRUQkTnG2FCYDK919VbSE58PABe0cfwnwUIz1dNnq1eGxktW6+khEEi3OUBgLrEvbror2tWBmRwCVwJ9irKfLmkKhgjXqPhKRRIszFFq70c3bOPZiYJa7N7b6QmbTzGyRmS2qra3NWoGZWrMGhhftZDD1aimISKLFGQpVwLi07XJgfRvHXkw7XUfuPt3dJ7r7xBEjRmSxxMysXg2VxbUwfDgUFnb77xcR6S5xhsLzwHgzqzSz/oQP/tnNDzKzo4BhwHMx1nJIVq+GyoJqdR2JSOLFFgru3gBcCTxOmGp7pru/ama3mtn5aYdeAjzs7m11LeXU/v2wdi1U+CqFgogkXqw3r7n7HGBOs303Ndu+Oc4aDtXGjeHmtcpdyxQKIpJ4sd68lgSpy1HrXtIgs4gknkKhA2vWhMeK/a8rFEQk8RQKHTjoHoXDDstpLSIicVModGD1ahg1fA9F7IYcXA4rItKdFAodWLMGKkqjZTgVCiKScAqFDqxeDZVDNocNhYKIJJxCoR0NDbBuHVQW1YQdpaW5LUhEJGYKhXZUV4dgqOhXBUOHQkFBrksSEYmVQqEdqXsU9r+uriMRyQsKhXY03aNQuWe5QkFE8oJCoR2rV4MZjKtfqlAQkbygUGjH6tVQXg79N29QKIhIXlAotGPNGqisdNi0SaEgInlBodCO1auhYsy+cAlSWVmuyxERiZ1CoQ179oRLUivL6sMOtRREJA8oFNqwdi24Q8Xgt8IOhYKI5AGFQhsWLw6PE8qqwhOFgojkAYVCGxYuhKIiOGbgqrBDoSAieUCh0IYFC+Ckk6DfltqwQwPNIpIHFAqt2LcPXngBJk8Gamth4MDwJSKScAqFVrz8crj66OSTCaGgriMRyRMKhVYsXBgeUy0FhYKI5AmFQisWLAjLMR9xBAoFEckrCoVWLFwYWglmhFDQILOI5AmFQjPbtsHy5VHXEWjeIxHJKwqFZhYtCncyn3wysHNn+FIoiEieUCg00zTIPGkSoesIFAoikjcUCs0sWABvfzsMG4ZCQUTyjkIhjXsIhdR4gkJBRPKMQiFNVRVs3BiNJ8CBUNDVRyKSJxQKaZYvD4/HHRft2LQpPKqlICJ5QqGQZuPG8Dh6dLSjthYKCmDIkJzVJCLSnRQKaWpqwuPIkdGOphvXzHJWk4hId1IopKmpgcJCKCmJdmiKCxHJM7GGgplNMbPXzGylmV3fxjEXmdlSM3vVzH4RZz0dqamBUaPSGgaa4kJE8ky/uF7YzPoCdwFnA1XA82Y2292Xph0zHrgBOM3dt5jZYXHVk4mNG9O6jiCEwkkn5aweEZHuFlsoAJOBle6+CsDMHgYuAJamHfM54C533wLg7m/GWE+HamqgoiJth7qPRBJj3759VFVVsXv37lyXEqvCwkLKy8spKCjo0s/HGQpjgXVp21XAyc2OeTuAmT0D9AVudvfHYqypXTU1cMop0ca+fWF2PIWCSCJUVVVRUlJCRUUFltCLR9ydzZs3U1VVRWVlZZdeI84xhdb+q3uz7X7AeOAM4BLgZ2Y2tMULmU0zs0Vmtqi26YayLGtsDA2DVPeR7lEQSZTdu3dTWlqa2EAAMDNKS0sPqTUUZyhUAePStsuB9a0c86i773P31cBrhJA4iLtPd/eJ7j5xREwf0ps2wf79aaGwPir1oEEGEenNkhwITQ71HOMMheeB8WZWaWb9gYuB2c2O+S1wJoCZlRG6k1bFWFObWtyj0HR781FH5aIcEUmYrVu38pOf/KTTP3fOOeewdevWGCpqXWyh4O4NwJXA48AyYKa7v2pmt5rZ+dFhjwObzWwpMB+4zt03x1VTe5ruZh41KtqxfDn07Qtve1suyhGRhGkrFBobG9v9uTlz5jB0aIte9djEOdCMu88B5jTbd1Pacwe+Gn3lVIuWwrJlcOSRMGBAzmoSkeS4/vrref3115kwYQIFBQUUFxczevRolixZwtKlS/nQhz7EunXr2L17N1dddRXTpk0DoKKigkWLFrF9+3amTp3K6aefzrPPPsvYsWN59NFHKSoqymqdsYZCb9Jq99E73pGzekQkRldfDUuWZPc1J0yA229v89vf+973eOWVV1iyZAlPPfUU5557Lq+88krqKqEZM2YwfPhwdu3axaRJk7jwwgspLS096DVWrFjBQw89xD333MNFF13Er3/9ay6//PKsnoamuYhs3AhFRdEUFw0NsGIFvPOduS5LRBJq8uTJB102escdd3D88cdzyimnsG7dOlasWNHiZyorK5kwYQIAJ510EmvWrMl6XWopRGpqQivBDFi9GvbuVUtBJKna+Yu+uwwaNCj1/KmnnuLJJ5/kueeeY+DAgZxxxhmtXlY6IK07u2/fvuzatSvrdamlEGkKBeDAlUcKBRHJkpKSEurr61v93rZt2xg2bBgDBw5k+fLl/O1vf+vm6g5QSyGycWMYVwYUCiKSdaWlpZx22mkcc8wxFBUVMTLtHqgpU6bw05/+lOOOO46jjjqKU1JTK3Q/hUKkpgZOPTXaWLYsNBuGDctpTSKSLL/4ResTQQ8YMIA//vGPrX6vadygrKyMV155JbX/2muvzXp9oO4jIExxsWmTrjwSEVEoEOY82r8/unHNPYSCrjwSkTykUKDZPQpvvglbtqilICJ5SaFAs1DQILOI5DGFAgdCYdQoDoSCuo9EJA8pFDgwGd7IkYQrjwYOhPLynNYkIpILCgVCS6GoCIqLOXDlUR/9pxGR7Onq1NkAt99+Ozt37sxyRa3TJx8hFEaNiqa40OWoIhKD3hIKunmN0H00ciSwYwesXQuf+UyuSxKRhEmfOvvss8/msMMOY+bMmezZs4cPf/jD3HLLLezYsYOLLrqIqqoqGhsbufHGG6mpqWH9+vWceeaZlJWVMX/+/FjrVCgQWgpHHgk88kjYoZaCSKLlYObsg6bOnjt3LrNmzWLhwoW4O+effz5PP/00tbW1jBkzhj/84Q9AmBNpyJAh/PjHP2b+/PmUlZVlt+hWqPsIqKlxRr2xED7xCZg0CaZMyXVJIpJgc+fOZe7cuZxwwgmceOKJLF++nBUrVnDsscfy5JNP8vWvf52//OUvDBkypNtry5+WwoIF8NRTLXY3NBq1b17LyDf/GLqN7rwTCgu7vz4R6Ta5njnb3bnhhhv4/Oc/3+J7ixcvZs6cOdxwww28//3v56abbmrlFeKTP6Hw9NNw/fUtdm9iJM6/MfLis+Ce06PRZhGR7EqfOvsDH/gAN954I5dddhnFxcVUV1dTUFBAQ0MDw4cP5/LLL6e4uJj77rvvoJ/tju6j/AmFq6+GK69ssbvmZYNTYNS/vAeUByISk/Sps6dOncqll17KqdHUzMXFxTzwwAOsXLmS6667jj59+lBQUMDdd98NwLRp05g6dSqjR4+OfaDZ3D3WX5BtEydO9EWLFnX652bMgP/6r5b7my44+utf4bTTslCgiPRIy5Yt4515MlNBa+dqZovdfWJHP5s3LYXSUjj66Na/d/bZcOKJ3VuPiEhPlDehcMEF4UtERNqmS1JFRCRFoSAieaO3jaF2xaGeo0JBRPJCYWEhmzdvTnQwuDubN2+m8BDutcqbMQURyW/l5eVUVVVRW1ub61JiVVhYSPkhTP2vUBCRvFBQUEBlZWWuy+jx1H0kIiIpCgUREUlRKIiISEqvm+bCzGqBtZ34kTJgU0zl9GT5eN75eM6Qn+edj+cMh3beR7j7iI4O6nWh0FlmtiiT+T6SJh/POx/PGfLzvPPxnKF7zlvdRyIikqJQEBGRlHwIhem5LiBH8vG88/GcIT/POx/PGbrhvBM/piAiIpnLh5aCiIhkKNGhYGZTzOw1M1tpZi0XaE4AMxtnZvPNbJmZvWpmV0X7h5vZE2a2Inoclutas83M+prZi2b2+2i70swWROf8SzPrn+sas83MhprZLDNbHr3np+bJe31N9P/3K2b2kJkVJu39NrMZZvammb2Stq/V99aCO6LPtpfNLGvLhCU2FMysL3AXMBU4GrjEzNpYe61XawC+5u7vBE4BvhSd5/XAPHcfD8yLtpPmKmBZ2vb3gduic94CfCYnVcXr/wKPufs7gOMJ55/o99rMxgJfASa6+zFAX+Bikvd+3wdMabavrfd2KjA++poG3J2tIhIbCsBkYKW7r3L3vcDDQOLWXnP3De7+QvS8nvAhMZZwrj+PDvs58KHcVBgPMysHzgV+Fm0bcBYwKzokiec8GPgn4F4Ad9/r7ltJ+Hsd6QcUmVk/YCCwgYS93+7+NPBWs91tvbcXAPd78DdgqJmNzkYdSQ6FscC6tO2qaF9imVkFcAKwABjp7hsgBAdwWO4qi8XtwL8B+6PtUmCruzdE20l8v48EaoH/ibrNfmZmg0j4e+3u1cCPgDcIYbANWEzy329o+72N7fMtyaFgrexL7KVWZlYM/Bq42t3rcl1PnMzsPOBNd1+cvruVQ5P2fvcDTgTudvcTgB0krKuoNVE/+gVAJTAGGEToPmkuae93e2L7/z3JoVAFjEvbLgfW56iWWJlZASEQHnT3R6LdNU3NyejxzVzVF4PTgPPNbA2hW/AsQsthaNS9AMl8v6uAKndfEG3PIoREkt9rgPcBq9291t33AY8A7yb57ze0/d7G9vmW5FB4HhgfXaHQnzAwNTvHNWWlP4KSAAAC5UlEQVRd1Jd+L7DM3X+c9q3ZwCej558EHu3u2uLi7je4e7m7VxDe1z+5+2XAfOCj0WGJOmcAd98IrDOzo6Jd7wWWkuD3OvIGcIqZDYz+f28670S/35G23tvZwCeiq5BOAbY1dTMdqkTfvGZm5xD+guwLzHD3/8xxSVlnZqcDfwH+zoH+9W8QxhVmAocT/lH9i7s3H8Tq9czsDOBadz/PzI4ktByGAy8Cl7v7nlzWl21mNoEwuN4fWAVcQfjjLtHvtZndAnyMcLXdi8BnCX3oiXm/zewh4AzCTKg1wLeB39LKexuF452Eq5V2Ale4+6Ks1JHkUBARkc5JcveRiIh0kkJBRERSFAoiIpKiUBARkRSFgoiIpCgURCJm1mhmS9K+sna3sJlVpM9+KdJT9ev4EJG8scvdJ+S6CJFcUktBpANmtsbMvm9mC6Ovt0X7jzCzedF89vPM7PBo/0gz+42ZvRR9vTt6qb5mdk+0LsBcMyuKjv+KmS2NXufhHJ2mCKBQEElX1Kz76GNp36tz98mEu0hvj/bdSZi++DjgQeCOaP8dwJ/d/XjC3ESvRvvHA3e5+7uArcCF0f7rgROi1/lCXCcnkgnd0SwSMbPt7l7cyv41wFnuviqafHCju5ea2SZgtLvvi/ZvcPcyM6sFytOnXIimNX8iWiwFM/s6UODu/2FmjwHbCVMa/Nbdt8d8qiJtUktBJDPexvO2jmlN+rw8jRwY0zuXsErgScDitJk/RbqdQkEkMx9Le3wuev4sYZZWgMuAv0bP5wFfhNQ60oPbelEz6wOMc/f5hEWDhgItWisi3UV/kYgcUGRmS9K2H3P3pstSB5jZAsIfUpdE+74CzDCz6wgrol0R7b8KmG5mnyG0CL5IWDGsNX2BB8xsCGHhlNuiJTZFckJjCiIdiMYUJrr7plzXIhI3dR+JiEiKWgoiIpKiloKIiKQoFEREJEWhICIiKQoFERFJUSiIiEiKQkFERFL+P9v8wVoonvk9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fda46d5a390>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(stats['accuracy']))+1, stats['accuracy'], color='red', label='train')\n",
    "plt.plot(np.arange(len(stats['val_accuracy']))+1, stats['val_accuracy'], color='blue', label='test')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Pen and Paper:\n",
    "1. Convince yourself of the equations in the slides. Add the missing indices?\n",
    "2. Compute $\\partial_j J$ for the crossentropy loss in the case of softmax and logistic in the last layer. Eq (28) and (32) in the slides.\n",
    "\n",
    "Deep Learning exercises:\n",
    "1. Implement more activation functions, such as leaky relu or tanh\n",
    "2. Use logistic/sigmoid in the last layer since we only have a 2 Classes classification problem.\n",
    "\n",
    "Physics exercises:\n",
    "1. Predict Hodge numbers; Data can be created with pyCICY package, but is also found in the github repository.\n",
    "    1. as Classification problem, with e.g. five classes being: $h^1 = {0,1,2,3,>3}$.\n",
    "    2. as Regression problem, $h^1 \\in \\mathbb{Z}_{\\ge 0}$. Reproduce results of Fabians paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hodge numbers of line bundles\n",
    "\n",
    "Hodge numbers of line bundles were one of the [first](https://arxiv.org/pdf/1706.07024.pdf) applications of ML techniques. Neural networks tend to have a harder time in regression problems and often do significantly better in classification problems. Thus, in [later](https://arxiv.org/pdf/1809.02547.pdf) [developments](https://arxiv.org/pdf/1906.08730.pdf) the focus was to identify polynomial cones of the hodge numbers.\n",
    "\n",
    "I've still got some data from our polynomial [paper](https://arxiv.org/pdf/1906.00392.pdf) where we used conventional curve fitting to identify the cones and their analytic expressions.\n",
    "\n",
    "You are welcome to use the data and reproduce these papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m0</th>\n",
       "      <th>m1</th>\n",
       "      <th>h0</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1861.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2484.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       m0    m1      h0   h1   h2    h3\n",
       "0   -10.0 -10.0     0.0  0.0  0.0  4060\n",
       "1   -10.0  -9.0     0.0  0.0  0.0  3215\n",
       "2   -10.0  -8.0     0.0  0.0  0.0  2484\n",
       "3   -10.0  -7.0     0.0  0.0  0.0  1861\n",
       "4   -10.0  -6.0     0.0  0.0  0.0  1340\n",
       "..    ...   ...     ...  ...  ...   ...\n",
       "436  10.0   6.0  1340.0  0.0  0.0     0\n",
       "437  10.0   7.0  1861.0  0.0  0.0     0\n",
       "438  10.0   8.0  2484.0  0.0  0.0     0\n",
       "439  10.0   9.0  3215.0  0.0  0.0     0\n",
       "440  10.0  10.0  4060.0  0.0  0.0     0\n",
       "\n",
       "[441 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h7806 = pd.read_csv('data/hodge/7806.csv', sep=' ', index_col=0)\n",
    "h7806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m0</th>\n",
       "      <th>m1</th>\n",
       "      <th>h0</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2975.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       m0    m1      h0   h1   h2    h3\n",
       "0   -10.0 -10.0     0.0  0.0  0.0  3730\n",
       "1   -10.0  -9.0     0.0  0.0  0.0  2975\n",
       "2   -10.0  -8.0     0.0  0.0  0.0  2316\n",
       "3   -10.0  -7.0     0.0  0.0  0.0  1749\n",
       "4   -10.0  -6.0     0.0  0.0  0.0  1270\n",
       "..    ...   ...     ...  ...  ...   ...\n",
       "436  10.0   6.0  1270.0  0.0  0.0     0\n",
       "437  10.0   7.0  1749.0  0.0  0.0     0\n",
       "438  10.0   8.0  2316.0  0.0  0.0     0\n",
       "439  10.0   9.0  2975.0  0.0  0.0     0\n",
       "440  10.0  10.0  3730.0  0.0  0.0     0\n",
       "\n",
       "[441 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h7882 = pd.read_csv('data/hodge/7882.csv', sep=' ', index_col=0)\n",
    "h7882"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
